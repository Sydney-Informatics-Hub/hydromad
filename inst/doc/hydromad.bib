@inproceedings{CrokeEtAl:2005,
    author = {Croke, B. F. W. and Andrews, F. and Jakeman, A. J. and Cuddy, S. and Luddy, A.},
    booktitle = {29th Hydrology and Water Resources Symposium},
    citeulike-article-id = {7750715},
    day = {21--23},
    location = {Canberra},
    month = {February},
    posted-at = {2010-09-01 02:50:42},
    priority = {1},
    title = {Redesign of the IHACRES rainfall-runoff model},
    year = {2005}
}

@article{ViviroliEtAl:2009,
    abstract = {Spatially distributed modelling is an important instrument for studying the hydrological cycle, both concerning its present state as well as possible future changes in climate and land use. Results of such simulations are particularly relevant for the fields of water resources, natural hazards and hydropower. The semi-distributed hydrological modelling system PREVAH (PREecipitation-Runoff-EVApotranspiration HRU Model) implements a conceptual process-oriented approach and has been developed especially to suit conditions in mountainous environments with their highly variable environmental and climatic conditions. This article presents an overview of the actual model core of PREVAH and introduces the various tools which have been developed for obtaining a comprehensive, user-friendly modelling system: DATAWIZARD for importing and managing hydrometeorological data, WINMET for pre-processing meteorological data, GRIDMATH for carrying out elementary raster data operations, FAOSOIL for processing FAO World Soil Map information, WINHRU for pre-processing spatial data and aggregating hydrological response units (HRU), WINPREVAH for operating the model, HYDROGRAPH for visualising hydrograph data and VIEWOPTIM for visualising the calibration procedure. The PREVAH components introduced here support a modelling task from pre-processing the data over the actual model calibration and validation to visualising and interpreting the results (post-processing). A brief overview of current PREVAH applications demonstrates the flexibility of the modelling system with examples that range from water balance modelling over flood estimation and flood forecasting to drought analysis in Switzerland, Austria, China, Russia and Sweden.},
    author = {Viviroli, D. and Zappa, M. and Gurtz, J. and Weingartner, R.},
    citeulike-article-id = {5123076},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2009.04.001},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815209000875},
    doi = {10.1016/j.envsoft.2009.04.001},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {software},
    month = {October},
    number = {10},
    pages = {1209--1222},
    posted-at = {2010-08-26 05:45:59},
    priority = {2},
    title = {An introduction to the hydrological modelling system PREVAH and its pre- and post-processing-tools},
    url = {http://dx.doi.org/10.1016/j.envsoft.2009.04.001},
    volume = {24},
    year = {2009}
}

@article{Willems:2009,
    abstract = {A multi-criteria model evaluation protocol is presented to check the performance of rainfall-runoff models during model calibration and validation phases based on a high frequency (e.g. hourly, daily) river flow series. The multiple criteria or objectives are based on multiple and non-commensurable measures of information derived from river flow series by means of a number of sequential time series processing tasks. These include separation of the river flow series in subflows, split of the series in nearly independent quick and slow flow hydrograph periods, and the extraction of nearly independent peak and low flows. The protocol accounts for the statistical assumptions and requirements on independency and homoscedasticity of the model residuals, significantly advanced through the use of nearly independent flow values extracted from the flow series. Next to the separate evaluation of the subflow recessions, the quick and slow runoff peak and low values and event volumes, also the performance of the model in predicting extreme high and low flow statistics is validated. To support the time series processing tasks as well as the application of the multi-criteria model evaluation protocol, a Microsoft Excel-based tool (WETSPRO: Water Engineering Time Series PROcessing tool) has been developed. It is based on the assessment of graphical displays, which complement traditional goodness-of-fit statistics.},
    author = {Willems, P.},
    citeulike-article-id = {4005794},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2008.09.005},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815208001606},
    doi = {10.1016/j.envsoft.2008.09.005},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {events},
    month = {March},
    number = {3},
    pages = {311--321},
    posted-at = {2010-08-25 01:32:13},
    priority = {0},
    title = {A time series tool to support the multi-criteria performance evaluation of rainfall-runoff models},
    url = {http://dx.doi.org/10.1016/j.envsoft.2008.09.005},
    volume = {24},
    year = {2009}
}

@article{DawsonEtAl:2010,
    abstract = {Hydro Test is an open access web resource that was established in 2005. This site offers a wide range of statistical metrics for the testing and evaluation of hydrological modelling outputs. In providing computational support to the international scientific community the authors are aiming to ensure that reported studies are based on consistent and accurate evaluations expressed in terms of recognised global standards. This article reports a number of recent improvements to the resource. These developments include a fresh user interface, additional statistical measures of model performance, a graphing facility, and an option to perform the simultaneous analysis of multiple model outputs. Through continuing development of this open access resource the authors are attempting to share and promote: the latest analytical procedures; discussions on current thinking; and a dynamic hydrological modelling tool that is evolving in parallel with its associated application domain.},
    author = {Dawson, C. W. and Abrahart, R. J. and See, L. M.},
    citeulike-article-id = {4778991},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2009.01.001},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815209000024},
    day = {01},
    doi = {10.1016/j.envsoft.2009.01.001},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {timeseries},
    month = {November},
    number = {11},
    pages = {1481--1482},
    posted-at = {2010-08-25 01:17:11},
    priority = {2},
    title = {HydroTest: Further development of a web resource for the standardised assessment of hydrological models},
    url = {http://dx.doi.org/10.1016/j.envsoft.2009.01.001},
    volume = {25},
    year = {2010}
}

@article{LittlewoodEtAl:2003,
    abstract = {No Abstract.},
    address = {Centre for Ecology and Hydrology, Wallingford OX10 8BB, UK; Integrated Catchment Assessment and Management Centre, Australian National University, Canberra, ACT 0200, Australia; Centre for Resource and Environmental Studies, Australian National University, Canberra, ACT 0200, Australia; Centre for Water Research, The University of Western Australia, Crawley, WA 6009, Australia},
    author = {Littlewood, I. G. and Croke, B. F. W. and Jakeman, A. J. and Sivapalan, M.},
    citeulike-article-id = {764747},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hyp.5129},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/104531891/ABSTRACT},
    doi = {10.1002/hyp.5129},
    journal = {Hydrol. Process.},
    keywords = {topdown},
    number = {8},
    pages = {1673--1679},
    posted-at = {2010-08-25 01:13:08},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {The role of 'top-down' modelling for Prediction in Ungauged Basins (PUB)},
    url = {http://dx.doi.org/10.1002/hyp.5129},
    volume = {17},
    year = {2003}
}

@inproceedings{AndrewsEtAl:2010,
    address = {Ottawa, Ontario, Canada},
    author = {Andrews, Felix T. and Croke, Barry F. W. and Jeanes, Kevin W.},
    booktitle = {Proceedings of the iEMSs Fifth Biennial Meeting: "Summit on Environmental Modelling and Software"},
    citeulike-article-id = {7654241},
    editor = {Swayne, D. and Et},
    keywords = {models},
    month = {July},
    organization = {International Environmental Modelling and Software Society},
    posted-at = {2010-08-16 01:02:19},
    priority = {2},
    title = {Robust estimation of the total unit hydrograph},
    year = {2010}
}

@article{LiuEtAl:2009,
    abstract = { Summary Within the GLUE methodology, there are a number of advantages of taking a limits of acceptability approach to model evaluation for non-ideal applications where the strong assumptions of statistical identification might be difficult to justify. However, there is a question of how the limits of acceptability might be specified in a way that reflects the different sources of uncertainty in the modeling process. Here, a novel method for identifying behavioural models in an extended GLUE methodology is developed and applied to an application of Dynamic TOPMODEL to the Attert catchment in Luxemburg with semi-distributed inputs to nested sub-catchments. The results raise some important issues about testing model structures as hypotheses of catchment responses. },
    author = {Liu, Yanli and Freer, Jim and Beven, Keith and Matgen, Patrick},
    citeulike-article-id = {7515692},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jhydrol.2009.01.016},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169409000110},
    day = {30},
    doi = {10.1016/j.jhydrol.2009.01.016},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {uncertainty},
    month = {March},
    number = {1-2},
    pages = {93--103},
    posted-at = {2010-07-20 04:28:05},
    priority = {4},
    title = {Towards a limits of acceptability approach to the calibration of hydrological models: Extending observation error},
    url = {http://dx.doi.org/10.1016/j.jhydrol.2009.01.016},
    volume = {367},
    year = {2009}
}

@article{BevenFreer:2001,
    abstract = {It may be endemic to mechanistic modelling of complex environmental systems that there are many different model structures and many different parameter sets within a chosen model structure that may be behavioural or acceptable in reproducing the observed behaviour of that system. This has been called the equifinality concept. The generalised likelihood uncertainty estimation (GLUE) methodology for model identification allowing for equifinality is described. Prediction within this methodology is a process of ensemble forecasting using a sample of parameter sets from the behavioural model space, with each sample weighted according to its likelihood measure to estimate prediction quantiles. This allows that different models may contribute to the ensemble prediction interval at different time steps and that the distributional form of the predictions may change over time. Any effects of model nonlinearity, covariation of parameter values and errors in model structure, input data or observed variables, with which the simulations are compared, are handled implicitly within this procedure. GLUE involves a number of choices that must be made explicit and can be therefore subjected to scrutiny and discussion. These include ways of combining information from different types of model evaluation or from different periods in a data assimilation context. An example application to rainfall-runoff modelling is used to illustrate the methodology, including the updating of likelihood measures.},
    author = {Beven, K. and Freer, J.},
    citeulike-article-id = {150278},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0022-1694(01)00421-8},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169401004218},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6V6C-43F71R2-4/2/64c651852b0e81f9edfa7285e830e840},
    day = {01},
    doi = {10.1016/S0022-1694(01)00421-8},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {uncertainty},
    month = {August},
    number = {1-4},
    pages = {11--29},
    posted-at = {2010-07-20 03:30:10},
    priority = {3},
    title = {Equifinality, data assimilation, and uncertainty estimation in mechanistic modelling of complex environmental systems using the GLUE methodology},
    url = {http://dx.doi.org/10.1016/S0022-1694(01)00421-8},
    volume = {249},
    year = {2001}
}

@article{BoyleEtAl:2000,
    abstract = {Automatic methods for model calibration seek to take advantage of  the speed and power of digital computers, while being},
    author = {Boyle, Douglas P. and Gupta, Hoshin V. and Sorooshian, Soroosh},
    citeulike-article-id = {4504981},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2000/2000WR900207.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2000WR900207},
    doi = {10.1029/2000WR900207},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {calibration},
    number = {12},
    pages = {3663--3674},
    posted-at = {2010-07-16 05:23:11},
    priority = {2},
    title = {Toward Improved Calibration of Hydrologic Models:  Combining the Strengths of Manual and Automatic Methods},
    url = {http://dx.doi.org/10.1029/2000WR900207},
    volume = {36},
    year = {2000}
}

@article{KatzEtAl:2002,
    abstract = {The statistics of extremes have played an important role in engineering practice for water resources design and management. How recent developments in the statistical theory of extreme values can be applied to improve the rigor of hydrologic applications and to make such analyses more physically meaningful is the central theme of this paper. Such methodological developments primarily relate to maximum likelihood estimation in the presence of covariates, in combination with either the block maxima or peaks over threshold approaches. Topics that are treated include trends in hydrologic extremes, with the anticipated intensification of the hydrologic cycle as part of global climate change. In an attempt to link downscaling (i.e., relating large-scale atmosphere–ocean circulation to smaller-scale hydrologic variables) with the statistics of extremes, statistical downscaling of hydrologic extremes is considered. Future challenges are reviewed, such as the development of more rigorous statistical methodology for regional analysis of extremes, as well as the extension of Bayesian methods to more fully quantify uncertainty in extremal estimation. Examples include precipitation and streamflow extremes, as well as economic damage associated with such extreme events, with consideration of trends and dependence on patterns in atmosphere–ocean circulation (e.g., El Ni\~{n}o phenomenon).},
    author = {Katz, Richard W. and Parlange, Marc B. and Naveau, Philippe},
    citeulike-article-id = {2910474},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0309-1708(02)00056-8},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0309170802000568},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6VCF-478RM4X-F/1/de9158ec204629203fbc9d1ad532cdb2},
    doi = {10.1016/S0309-1708(02)00056-8},
    issn = {03091708},
    journal = {Advances in Water Resources},
    keywords = {events, statistics},
    month = {August},
    number = {8-12},
    pages = {1287--1304},
    posted-at = {2010-07-16 05:19:24},
    priority = {0},
    title = {Statistics of extremes in hydrology},
    url = {http://dx.doi.org/10.1016/S0309-1708(02)00056-8},
    volume = {25},
    year = {2002}
}

@article{MadsenEtAl:1997,
    abstract = {Two different models for analyzing extreme hydrologic events, based 			 on, respectively, partial duration series (PDS) and},
    author = {Madsen, Henrik and Rasmussen, Peter F. and Rosbjerg, Dan},
    citeulike-article-id = {7497624},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/1997/96WR03848.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/96WR03848},
    doi = {10.1029/96WR03848},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {events, statistics},
    number = {4},
    pages = {null+},
    posted-at = {2010-07-16 05:17:28},
    priority = {1},
    title = {Comparison of Annual Maximum Series and Partial Duration 			 Series Methods for Modeling Extreme Hydrologic Events 1. At-Site 			 Modeling},
    url = {http://dx.doi.org/10.1029/96WR03848},
    volume = {33}
}

@article{LangEtAl:1999,
    abstract = {Annual maximum flood (AMF) sampling remains the most popular approach to flood frequency analysis. An alternative, the  ” peaks over threshold” (POT) approach, deals with the selection of over-threshold values. However, the POT approach remains under-employed mainly because of the complexities associated with its use. Among the difficulties are the choice of threshold and the selection of criteria for retaining flood peaks. The literature remains sparse and incoherent concerning the various elements and complexities of the POT model. The purpose of the present paper is to shed some light on some of the recurrent and most important questions with regard to the practice of POT modeling, and to make a first step in establishing a set of coherent practice-oriented guidelines for the use of the POT model. This paper reviews tests and methods useful for modeling the process of over-threshold values, the choice of the threshold level, the verification of the independence of the values and the stationarity of the process, and also presents an application.},
    author = {Lang, M. and Ouarda, T. and Bobee, B.},
    citeulike-article-id = {7497570},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0022-1694(99)00167-5},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169499001675},
    day = {06},
    doi = {10.1016/S0022-1694(99)00167-5},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {events},
    month = {December},
    number = {3-4},
    pages = {103--117},
    posted-at = {2010-07-16 05:04:19},
    priority = {2},
    title = {Towards operational guidelines for over-threshold modeling},
    url = {http://dx.doi.org/10.1016/S0022-1694(99)00167-5},
    volume = {225},
    year = {1999}
}

@article{YangEtAl:2007,
    abstract = {Calibration and uncertainty analysis in hydrologic modeling are affected by measurement errors in input and response and errors                     in model structure. Recently, extending similar approaches in discrete time, a continuous time autoregressive error model                     was proposed for statistical inference and uncertainty analysis in hydrologic modeling. The major advantages over discrete                     time formulation are the use of a continuous time error model for describing continuous processes, the possibility of accounting                     for seasonal variations of parameters in the error model, the easier treatment of missing data or omitted outliers, and the                     opportunity for continuous time predictions. The model was developed for the Chaohe Basin in China and had some features specific                     for this semiarid climatic region (in particular, the seasonal variation of parameters in the error model in response to seasonal                     variation in precipitation). This paper tests and extends this approach with an application to the Thur River basin in Switzerland,                     which is subject to completely different climatic conditions. This application corroborates the general applicability of the                     approach but also demonstrates the necessity of accounting for the heavy tails in the distributions of residuals and innovations.                     This is done by replacing the normal distribution of the innovations by a Student t distribution, the degrees of freedom of which are adapted to best represent the shape of the empirical distribution of the                     innovations. We conclude that with this extension, the continuous time autoregressive error model is applicable and flexible                     for hydrologic modeling under different climatic conditions. The major remaining conceptual disadvantage is that this class                     of approaches does not lead to a separate identification of model input and model structural errors. The major practical disadvantage                     is the high computational demand characteristic for all Markov chain Monte Carlo techniques.},
    author = {Yang, Jing and Reichert, Peter and Abbaspour, Karim C.},
    citeulike-article-id = {7496382},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2007/2006WR005497.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2006WR005497},
    day = {2},
    doi = {10.1029/2006WR005497},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {statistics, uncertainty},
    month = {October},
    number = {10},
    pages = {W10401+},
    posted-at = {2010-07-16 01:12:29},
    priority = {2},
    title = {Bayesian uncertainty analysis in distributed hydrologic modeling: A case study in the Thur River basin (Switzerland)},
    url = {http://dx.doi.org/10.1029/2006WR005497},
    volume = {43},
    year = {2007}
}

@inbook{LeavesleyEtAl:2006,
    author = {Leavesley, G. H. and Markstrom, S. L. and Viger, R. J.},
    booktitle = {Watershed Models},
    citeulike-article-id = {7468385},
    editor = {Singh, V. P. and Frevert, D. K.},
    keywords = {software},
    pages = {159--177},
    posted-at = {2010-07-13 07:43:30},
    priority = {2},
    publisher = {CRC Press},
    title = {USGS Modular Modeling System (MMS) –- Precipitation-Runoff Modeling System (PRMS)},
    year = {2006}
}

@inproceedings{KimEtAl:2007,
    author = {Kim, H. S. and Croke, B. F. W. and Jakeman, A. J. and Chiew, F. H. S. and Mueller, N.},
    booktitle = {MODSIM 2007 International Congress on Modelling and Simulation},
    citeulike-article-id = {7468234},
    editor = {Oxley, L. and Kulasiri, D.},
    month = {December},
    organization = {Modelling and Simulation Society of Australia and New Zealand},
    pages = {74--80},
    posted-at = {2010-07-13 02:01:22},
    priority = {2},
    title = {Towards Separation of Climate and Land Use Effects on Hydrology: data analysis of the Googong and Cotter Catchments},
    year = {2007}
}

@article{BoxCox:1964,
    abstract = {In the analysis of data it is often assumed that observations y<sub>1</sub>, y<sub>2</sub>, ..., y<sub>n</sub> are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.},
    author = {Box, G. E. P. and Cox, D. R.},
    citeulike-article-id = {1989868},
    citeulike-linkout-0 = {http://www.jstor.org/stable/2984418},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {statistics},
    number = {2},
    pages = {211--252},
    posted-at = {2010-07-12 12:21:15},
    priority = {1},
    title = {An Analysis of Transformations},
    url = {http://www.jstor.org/stable/2984418},
    volume = {26},
    year = {1964}
}

@article{SelleHannah:2010,
    abstract = {Catchment models simulate water and solute dynamics at catchment scales and are invaluable tools for natural resource management. Parameters for catchment models can provide useful information about the importance of the hydrological processes involved. We propose and demonstrate a bootstrap approach to assess parameter uncertainty in dynamic catchment models. This approach, which is non-Bayesian and essentially non-parametric, requires no distributional assumptions about parameters and only weak assumptions about the distributional form of the model residuals. It is able to handle autocorrelated model errors which are very common in the application of dynamic hydrological models at catchment scales. The ability of our bootstrap approach to assess parameter uncertainty is demonstrated using numerical experiments with the abc hydrological model and an application of a conceptual model of salt load from an irrigated catchment in southeastern Australia.},
    author = {Selle, Benny and Hannah, Murray},
    citeulike-article-id = {7000015},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2010.03.005},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815210000502},
    day = {03},
    doi = {10.1016/j.envsoft.2010.03.005},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {statistics, timeseries},
    month = {August},
    number = {8},
    pages = {919--926},
    posted-at = {2010-05-12 00:45:31},
    priority = {3},
    title = {A bootstrap approach to assess parameter uncertainty in simple catchment models},
    url = {http://dx.doi.org/10.1016/j.envsoft.2010.03.005},
    volume = {25},
    year = {2010}
}

@inproceedings{KokkonenEtAl:2006,
    address = {Burlington, USA},
    author = {Kokkonen, Teemu and Koivusalo, Harri and Jakeman, Anthony and Norton, John},
    booktitle = {Proceedings of the iEMSs Third Biennial Meeting: "Summit on Environmental Modelling and Software"},
    citeulike-article-id = {7133320},
    editor = {Voinov, A. and Jakeman, A. J. and Rizzoli, A. E.},
    keywords = {models},
    month = {July},
    organization = {International Environmental Modelling and Software Society},
    posted-at = {2010-05-07 02:41:14},
    priority = {2},
    title = {Construction of a Degree-Day Snow Model in the Light of the ``Ten Iterative Steps in Model Development''},
    year = {2006}
}

@book{PriceEtAl:2006,
    abstract = {{<P>Problems demanding globally optimal solutions are ubiquitous, yet many are intractable when they involve constrained functions having many local optima and interacting, mixed-type variables.</P> <P>The differential evolution (DE) algorithm is a practical approach to global numerical optimization which is easy to understand, simple to implement, reliable, and fast. Packed with illustrations, computer code, new insights, and practical advice, this volume explores DE in both principle and practice. It is a valuable resource for professionals needing a proven optimizer and for students wanting an evolutionary perspective on global numerical optimization. </P> <P>A companion CD includes DE-based optimization software in several programming languages.</P>}},
    author = {Price, Kenneth and Storn, Rainer M. and Lampinen, Jouni A.},
    citeulike-article-id = {2194121},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3540209506},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3540209506},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3540209506},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3540209506},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3540209506/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540209506},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3540209506},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3540209506},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3540209506\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3540209506},
    day = {22},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {3540209506},
    keywords = {software},
    month = {December},
    posted-at = {2010-05-06 04:46:06},
    priority = {2},
    publisher = {Springer},
    title = {Differential Evolution: A Practical Approach to Global Optimization (Natural Computing Series)},
    url = {http://www.worldcat.org/isbn/3540209506},
    year = {2005}
}

@article{ClarkEtAl:2008,
    abstract = {The problems of identifying the most appropriate model structure for a given problem and quantifying the uncertainty in model                     structure remain outstanding research challenges for the discipline of hydrology. Progress on these problems requires understanding                     of the nature of differences between models. This paper presents a methodology to diagnose differences in hydrological model                     structures: the Framework for Understanding Structural Errors (FUSE). FUSE was used to construct 79 unique model structures                     by combining components of 4 existing hydrological models. These new models were used to simulate streamflow in two of the                     basins used in the Model Parameter Estimation Experiment (MOPEX): the Guadalupe River (Texas) and the French Broad River (North                     Carolina). Results show that the new models produced simulations of streamflow that were at least as good as the simulations                     produced by the models that participated in the MOPEX experiment. Our initial application of the FUSE method for the Guadalupe                     River exposed relationships between model structure and model performance, suggesting that the choice of model structure is                     just as important as the choice of model parameters. However, further work is needed to evaluate model simulations using multiple                     criteria to diagnose the relative importance of model structural differences in various climate regimes and to assess the                     amount of independent information in each of the models. This work will be crucial to both identifying the most appropriate                     model structure for a given problem and quantifying the uncertainty in model structure. To facilitate research on these problems,                     the FORTRAN-90 source code for FUSE is available upon request from the lead author.},
    author = {Clark, Martyn P. and Slater, Andrew G. and Rupp, David E. and Woods, Ross A. and Vrugt, Jasper A. and Gupta, Hoshin V. and Wagener, Thorsten and Hay, Lauren E.},
    citeulike-article-id = {7130889},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2008/2007WR006735.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2007WR006735},
    day = {13},
    doi = {10.1029/2007WR006735},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {software},
    month = {August},
    number = {12},
    pages = {W00B02+},
    posted-at = {2010-05-06 00:38:56},
    priority = {2},
    title = {Framework for Understanding Structural Errors (FUSE): A modular framework to diagnose differences between hydrological models},
    url = {http://dx.doi.org/10.1029/2007WR006735},
    volume = {44},
    year = {2008}
}

@article{ArgentEtAl:2009,
    abstract = {The concepts and technology of environmental decision support systems (EDSS) have developed considerably over recent decades, although core concepts such as flexibility and adaptability within a changing decision environment remain paramount. Much recent EDSS theory has focussed on model integration and re-use in decision support system (DSS) tools and for design and construction of 'DSS generators'. Many current specific DSS have architectures, tools, models and operational characteristics that are either fixed or difficult to change in the face of changing management needs. This paper reports on development and deployment of an EDSS that encompasses a new approach to DSS tools, generators and specific DSS applications. The system, named E2, is built upon a conceptualisation of terrestrial and aquatic environmental systems that has resulted in a robust and flexible system architecture. The architecture provides a set of base classes to represent fundamental concepts, and which can be instantiated and combined to form DSS generators of varying complexity. A DSS generator is described within which system users are able to select and link models, data, analysis tools and reporting tools to create specific DSS for particular problems, and for which new models and tools can be created and, through software reflection (introspection), discovered to provide expanded capability where required. This system offers a new approach within which environmental systems can be described in the form of specific DSS at a scale and level of complexity suited to the problems and needs of decision makers.},
    author = {Argent, R. M. and Perraud, J. M. and Rahman, J. M. and Grayson, R. B. and Podger, G. M.},
    citeulike-article-id = {7129685},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2008.12.010},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815208002351},
    doi = {10.1016/j.envsoft.2008.12.010},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {software},
    month = {July},
    number = {7},
    pages = {809--818},
    posted-at = {2010-05-05 15:55:30},
    priority = {2},
    title = {A new approach to water quality modelling and environmental decision support systems},
    url = {http://dx.doi.org/10.1016/j.envsoft.2008.12.010},
    volume = {24},
    year = {2009}
}

@inbook{Burnash:1995,
    address = {Highlands Ranch, Colo.},
    author = {Burnash, R. J. C.},
    booktitle = {Computer models of watershed hydrology},
    citeulike-article-id = {7117481},
    edition = {Revised},
    editor = {Singh, Vijay P.},
    keywords = {models},
    posted-at = {2010-05-03 02:32:09},
    priority = {2},
    publisher = {Water Resources Publications},
    title = {The NWS River Forecast System -- Catchment Modeling},
    year = {1995}
}

@article{VrugtEtAl:2009,
    abstract = {Markov chain Monte Carlo (MCMC) methods have found widespread use in many fields of study to estimate the average properties of complex systems, and for posterior inference in a Bayesian framework. Existing theory and experiments prove convergence of well-constructed MCMC schemes to the appropriate limiting distribution under a variety of different conditions. In practice, however this convergence is often observed to be disturbingly slow. This is frequently caused by an inappropriate selection of the proposal distribution used to generate trial moves in the Markov Chain. Here we show that significant improvements to the efficiency of MCMC simulation can be made by using a self-adaptive Differential Evolution learning strategy within a population-based evolutionary framework. This scheme, entitled Differential Evolution Adaptive Metropolis or DREAM, runs multiple different chains simultaneously for global exploration, and automatically tunes the scale and orientation of the proposal distribution in randomized subspaces during the search. Ergodicity of the algorithm is proved, and various examples involving nonlinearity, high-dimensionality, and multimodality show that DREAM is generally superior to other adaptive MCMC sampling approaches. The DREAM scheme significantly enhances the applicability of MCMC simulation to complex, multi-modal search problems.},
    author = {Vrugt, J. A. and ter Braak, C. J. F. and Diks, C. G. H. and Robinson, B. A. and Hyman, J. M. and Higdon, D.},
    citeulike-article-id = {7117345},
    journal = {International Journal of Nonlinear Sciences and Numerical Simulation},
    keywords = {software, statistics},
    number = {3},
    pages = {273--290},
    posted-at = {2010-05-03 01:09:29},
    priority = {0},
    title = {Accelerating Markov chain Monte Carlo simulation by differential evolution with self-adaptive randomized subspace sampling},
    volume = {10},
    year = {2009}
}

@article{SoetaertPetzoldt:2010,
    author = {Soetaert, Karline and Petzoldt, Thomas},
    citeulike-article-id = {7099652},
    citeulike-linkout-0 = {http://www.jstatsoft.org/v33/i03/},
    journal = {Journal of Statistical Software},
    keywords = {software},
    number = {3},
    pages = {1--28},
    posted-at = {2010-04-29 04:54:39},
    priority = {2},
    title = {Inverse Modelling, Sensitivity and Monte Carlo Analysis in {R} Using Package {FME}},
    url = {http://www.jstatsoft.org/v33/i03/},
    volume = {33},
    year = {2010}
}

@article{Wickham:2007,
    author = {Wickham, Hadley},
    citeulike-article-id = {7099651},
    citeulike-linkout-0 = {http://www.jstatsoft.org/v21/i12/paper},
    journal = {Journal of Statistical Software},
    keywords = {software},
    number = {12},
    posted-at = {2010-04-29 04:54:39},
    priority = {2},
    title = {Reshaping data with the reshape package},
    url = {http://www.jstatsoft.org/v21/i12/paper},
    volume = {21},
    year = {2007}
}

@book{Wickham:2009,
    author = {Wickham, Hadley},
    citeulike-article-id = {7099650},
    citeulike-linkout-0 = {http://had.co.nz/ggplot2/book},
    keywords = {software},
    posted-at = {2010-04-29 04:54:39},
    priority = {2},
    publisher = {Springer New York},
    title = {ggplot2: elegant graphics for data analysis},
    url = {http://had.co.nz/ggplot2/book},
    year = {2009}
}

@article{Williams:2009,
    author = {Williams, Graham J.},
    citeulike-article-id = {7099649},
    citeulike-linkout-0 = {http://journal.r-project.org/archive/2009-2/RJournal\_2009-2\_Williams.pdf},
    journal = {The R Journal},
    keywords = {software},
    month = {December},
    number = {2},
    pages = {45--55},
    posted-at = {2010-04-29 04:54:39},
    priority = {2},
    title = {Rattle: A Data Mining GUI for R},
    url = {http://journal.r-project.org/archive/2009-2/RJournal\_2009-2\_Williams.pdf},
    volume = {1},
    year = {2009}
}

@article{PerrinEtAl:2003,
    abstract = {Hydrologists have been struggling over the past decades to improve rainfall-runoff models. As a consequence, models proposed 20–30 years ago still keep evolving as progress is made in the understanding of catchment hydrological behaviour. Here we present the GR4J model, a daily lumped rainfall-runoff model which is the result of a continuous improvement process over the last 15 years. The article provides the mathematical formulation of a new four-parameter version of the model. Model performance is assessed on a large sample of catchments: compared to other rainfall-runoff models, the GR4J performance is among the best ones. It also gives better results than the previous three-parameter model version, especially in the simulation of low flows. The tests indicate that a four-parameter structure corresponds to the maximum level of complexity that could be afforded in the model. Adding more free parameters did not bring significant improvements. The gain in model robustness with this new version should enhance the confidence in the practical use of this simple model for water engineering and resource management. The discussion underlines the potential limits introduced in the modelling process when one relies on a priori concepts in building a model structure and it stresses the value of large catchment samples to assess models.},
    author = {Perrin, C. and Michel, C. and Andreassian, V.},
    citeulike-article-id = {7094590},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0022-1694(03)00225-7},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169403002257},
    day = {25},
    doi = {10.1016/S0022-1694(03)00225-7},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {models},
    month = {August},
    number = {1-4},
    pages = {275--289},
    posted-at = {2010-04-28 01:57:10},
    priority = {2},
    title = {Improvement of a parsimonious model for streamflow simulation},
    url = {http://dx.doi.org/10.1016/S0022-1694(03)00225-7},
    volume = {279},
    year = {2003}
}

@article{KitandisBras:1980,
    abstract = {The results from an application of a conceptual hydrologic model, 			 combined with filtering and statistical estimation methods,},
    author = {Kitanidis, Peter K. and Bras, Rafael L.},
    citeulike-article-id = {7094528},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/1980/WR016i006p01034.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/WR016i006p01034},
    doi = {10.1029/WR016i006p01034},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {statistics},
    number = {6},
    pages = {null+},
    posted-at = {2010-04-28 01:19:44},
    priority = {1},
    title = {Real-Time Forecasting With a Conceptual 			 Hydrologic Model 2. Applications and Results},
    url = {http://dx.doi.org/10.1029/WR016i006p01034},
    volume = {16}
}

@article{Kirchner:2009,
    abstract = {Water fluxes in catchments are controlled by physical processes and material properties that are complex, heterogeneous, and
                     poorly characterized by direct measurement. As a result, parsimonious theories of catchment hydrology remain elusive. Here
                     I describe how one class of catchments (those in which discharge is determined by the volume of water in storage) can be characterized
                     as simple first-order nonlinear dynamical systems, and I show that the form of their governing equations can be inferred directly
                     from measurements of streamflow fluctuations. I illustrate this approach using data from the headwaters of the Severn and
                     Wye rivers at Plynlimon in mid-Wales. This approach leads to quantitative estimates of catchment dynamic storage, recession
                     time scales, and sensitivity to antecedent moisture, suggesting that it is useful for catchment characterization. It also
                     yields a first-order nonlinear differential equation that can be used to directly simulate the streamflow hydrograph from
                     precipitation and evapotranspiration time series. This single-equation rainfall-runoff model predicts streamflow at Plynlimon
                     as accurately as other models that are much more highly parameterized. It can also be analytically inverted; thus, it can
                     be used to  ” do hydrology backward,” that is, to infer time series of whole-catchment precipitation directly from fluctuations
                     in streamflow. At Plynlimon, precipitation rates inferred from streamflow fluctuations agree with rain gauge measurements
                     as closely as two rain gauges in each catchment agree with each other. These inferred precipitation rates are not calibrated
                     to precipitation measurements in any way, making them a strong test of the underlying theory. The same approach can be used
                     to estimate whole-catchment evapotranspiration rates during rainless periods. At Plynlimon, evapotranspiration rates inferred
                     from streamflow fluctuations exhibit seasonal and diurnal cycles that agree semiquantitatively with Penman-Monteith estimates.
                     Thus, streamflow hydrographs may be useful for reconstructing precipitation and evapotranspiration records where direct measurements
                     are unavailable, unreliable, or unrepresentative at the scale of the landscape.
                  },
    author = {Kirchner, James W.},
    citeulike-article-id = {4104887},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2009/2008WR006912.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2008WR006912},
    day = {25},
    doi = {10.1029/2008WR006912},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {grand, models, timeseries},
    month = {February},
    number = {2},
    pages = {W02429+},
    posted-at = {2010-04-28 01:04:06},
    priority = {5},
    title = {Catchments as simple dynamical systems: Catchment characterization, rainfall-runoff modeling, and doing hydrology backward},
    url = {http://dx.doi.org/10.1029/2008WR006912},
    volume = {45},
    year = {2009}
}

@book{BeckerEtAl:1988,
    address = {Pacific Grove, CA, USA},
    author = {Becker, Richard A. and Chambers, John M. and Wilks, Allan R.},
    citeulike-article-id = {7086953},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/053409192X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/053409192X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/053409192X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/053409192X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/053409192X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/053409192X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/053409192X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN053409192X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=053409192X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/053409192X},
    howpublished = {Paperback},
    isbn = {053409192X},
    posted-at = {2010-04-27 04:24:04},
    priority = {1},
    publisher = {Wadsworth \& Brooks/Cole},
    title = {The New S Language: A Programming Environment for Data Analysis and Graphics},
    url = {http://www.worldcat.org/isbn/053409192X},
    year = {1988}
}

@article{ClevelandEtAl:1990,
    author = {Cleveland, R. B. and Cleveland, W. S. and McRae, J. E. and Terpenning, I.},
    citeulike-article-id = {7067214},
    journal = {Journal of Official Statistics},
    keywords = {statistics},
    pages = {3--73},
    posted-at = {2010-04-23 04:56:01},
    priority = {2},
    title = {STL: A Seasonal-Trend Decomposition Procedure Based on Loess},
    volume = {6},
    year = {1990}
}

@inbook{WheaterEtAl:1993,
    address = {Chichester},
    author = {Wheater, H. S. and Jakeman, A. J. and Beven, K. J.},
    booktitle = {Modelling Change in Environmental Systems},
    citeulike-article-id = {7055064},
    editor = {Jakeman, A. J. and Beck, M. B. and McAllen, M. J.},
    keywords = {grand},
    pages = {101--132},
    posted-at = {2010-04-22 01:19:14},
    priority = {2},
    publisher = {John Wiley},
    title = {Progress and directions in rainfall-runoff modelling},
    year = {1993}
}

@article{DawsonEtAl:2007,
    abstract = {This paper presents details of an open access web site that can be used by hydrologists and other scientists to evaluate time series models. There is at present a general lack of consistency in the way in which hydrological models are assessed that handicaps the comparison of reported studies and hinders the development of superior models. The HydroTest web site provides a wide range of objective metrics and consistent tests of model performance to assess forecasting skill. This resource is designed to promote future transparency and consistency between reported models and includes an open forum that is intended to encourage further discussion and debate on the topic of hydrological performance evaluation metrics. It is envisaged that the provision of such facilities will lead to the creation of superior forecasting metrics and the development of international benchmark time series datasets.},
    author = {Dawson, C. and Abrahart, R. and See, L.},
    citeulike-article-id = {4005832},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2006.06.008},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815206001642},
    doi = {10.1016/j.envsoft.2006.06.008},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {software},
    month = {July},
    number = {7},
    pages = {1034--1052},
    posted-at = {2010-04-21 07:39:55},
    priority = {2},
    title = {HydroTest: A web-based toolbox of evaluation metrics for the standardised assessment of hydrological forecasts},
    url = {http://dx.doi.org/10.1016/j.envsoft.2006.06.008},
    volume = {22},
    year = {2007}
}

@article{Boughton:2004,
    abstract = {The Australian water balance model (AWBM) is a catchment water balance model that calculates runoff from rainfall at daily or hourly time increments. The daily version iss used for water yield and water management studies; the hourly version is used for design flood estimation. This paper describes the origin and development of the AWBM beginning with elementary modelling components of saturation overland flow. A particular feature of the AWBM is the development of model-specific calibration procedures based on the model structure, including a graphical analysis of rainfall and runoff data, multiple linear regression and an automatic self-calibrating procedure. Application of the model for daily streamflow simulation is illustrated using data from 19 catchments located across Australia. Application at hourly time steps for design flood estimation is demonstrated on three catchments in Victoria. A procedure for use of the model to estimate daily streamflows on ungauged catchments is illustrated using the 19 catchments from the water yield study. Applications of the model in several research programs are described.},
    author = {Boughton, W.},
    citeulike-article-id = {6903695},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2003.10.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815203002196},
    doi = {10.1016/j.envsoft.2003.10.007},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {models},
    month = {October},
    number = {10},
    pages = {943--956},
    posted-at = {2010-03-25 05:20:04},
    priority = {2},
    title = {The Australian water balance model},
    url = {http://dx.doi.org/10.1016/j.envsoft.2003.10.007},
    volume = {19},
    year = {2004}
}

@inproceedings{Croke:2009,
    author = {Croke, B. F. W.},
    booktitle = {18th World IMACS Congress and MODSIM09 International Congress on Modelling and Simulation},
    citeulike-article-id = {6779160},
    citeulike-linkout-0 = {http://www.mssanz.org.au/modsim09/I7/croke.pdf},
    citeulike-linkout-1 = {http://www.google.com.au/search?q=croke+2009+modsim\&\#38;ie=utf-8\&\#38;oe=utf-8\&\#38;aq=t\&\#38;rls=org.mozilla:en-GB:official\&\#38;client=firefox-a},
    editor = {Anderssen, R. S. and Braddock, R. D. and Newham, L. T. H.},
    isbn = {978-0-9758400-7-8},
    month = {July},
    organization = {Modelling and Simulation Society of Australia and New Zealand and International Association for Mathematics and Computers in Simulation},
    pages = {3372--3378},
    posted-at = {2010-03-09 05:46:52},
    priority = {2},
    title = {Representing uncertainty in objective functions: extension to include the influence of serial correlation.},
    url = {http://www.mssanz.org.au/modsim09/I7/croke.pdf},
    year = {2009}
}

@article{NashSutcliffe:1970,
    abstract = {The principles governing the application of the conceptual model technique to river flow forecasting are discussed. The necessity for a systematic approach to the development and testing of the model is explained and some preliminary ideas suggested.},
    author = {Nash, J. and Sutcliffe, J.},
    citeulike-article-id = {101879},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0022-1694(70)90255-6},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0022169470902556},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6V6C-487FF7C-1XH/2/4bba4b13a68e4942542254b2ec23796b},
    doi = {10.1016/0022-1694(70)90255-6},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {statistics, timeseries},
    month = {April},
    number = {3},
    pages = {282--290},
    posted-at = {2010-03-08 23:42:44},
    priority = {2},
    title = {River flow forecasting through conceptual models part I - A discussion of principles},
    url = {http://dx.doi.org/10.1016/0022-1694(70)90255-6},
    volume = {10},
    year = {1970}
}

@article{Young:2008,
    author = {Young, Peter C.},
    citeulike-article-id = {6765982},
    citeulike-linkout-0 = {http://dx.doi.org/10.3166/jesa.42.149-179},
    day = {30},
    doi = {10.3166/jesa.42.149-179},
    issn = {12696935},
    journal = {Journal Europ\'{e}en des Syst\`{e}mes Automatis\'{e}s},
    keywords = {statistics, timeseries},
    month = {April},
    number = {2-3},
    pages = {149--179},
    posted-at = {2010-03-05 04:25:59},
    priority = {2},
    title = {The refined instrumental variable method},
    url = {http://dx.doi.org/10.3166/jesa.42.149-179},
    volume = {42},
    year = {2008}
}

@article{JakemanEtAl:1991,
    abstract = {The paper presents an identification procedure for a dynamic model of am hydrologic process. The process involves solute transport in streams subject to aquifer interaction and unsteady flows and the intended use of the model is prediction. Detailed assumptions and results are provided to illustrate the level of comprehensive analysis required to assess model adequacy. The assessment procedure easily generalizes to any dynamic model which is linear-in-the-parameters. As a fundamental tool, instrumental variable algorithms can be adopted which have a number of attractive features. These algorithms make both model-order identification and specification among alternatives a straightforward task. They are known to be consistent estimators in the presence of a wide class of errors. It is seen that they can be made stable and robust in the presence of data outliers. Instrumental variable algorithms can also be used which are asymptotically efficient and provide a covariance matrix of parameter estimates. The paper shows how they aid the quantification of predictive uncertainty and investigates the validity of the underlying assumptions. Further, it illustrates that, when instrumental variable algorithms are used in recursive mode, they can be used not only as an additional tool to access model inadequacy but also as an aid to model improvements.},
    address = {Australian National University, Australia},
    author = {Jakeman, A. J. and Thomas, G. A. and Dietrich, C. R.},
    citeulike-article-id = {6765949},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/for.3980100307},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/113452366/ABSTRACT},
    doi = {10.1002/for.3980100307},
    issn = {1099-131X},
    journal = {Journal of Forecasting},
    keywords = {ihacres},
    number = {3},
    pages = {319--346},
    posted-at = {2010-03-05 04:08:22},
    priority = {1},
    title = {System identification and validation for output prediction of a dynamic hydrologic process},
    url = {http://dx.doi.org/10.1002/for.3980100307},
    volume = {10},
    year = {1991}
}

@book{Sarkar:2008,
    abstract = {{R is rapidly growing in popularity as the environment of choice for data analysis and graphics both in academia and industry. Lattice brings the proven design of Trellis graphics (originally developed for S by William S. Cleveland and colleagues at Bell Labs) to R, considerably expanding its capabilities in the process. Lattice is a powerful and elegant high level data visualization system that is sufficient for most everyday graphics needs, yet flexible enough to be easily extended to handle demands of cutting edge research. Written by the author of the lattice system, this book describes it in considerable depth, beginning with the essentials and systematically delving into specific low levels details as necessary. No prior experience with lattice is required to read the book, although basic familiarity with R is assumed.   <P>The book contains close to150 figures produced with lattice. Many of the examples emphasize principles of good graphical design; almost all use real data sets that are publicly available in various R packages. All code and figures in the book are also available online, along with supplementary material covering more advanced topics. </P>}},
    author = {Sarkar, Deepayan},
    citeulike-article-id = {2757795},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387759689},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387759689},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/191760008},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387759689},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387759689},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387759689/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387759689},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387759689},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387759689},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387759689\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387759689},
    day = {12},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0387759689},
    keywords = {software, statistics},
    month = {March},
    posted-at = {2009-10-29 01:29:49},
    priority = {0},
    publisher = {Springer},
    title = {Lattice: Multivariate Data Visualization with R (Use R)},
    url = {http://www.worldcat.org/isbn/0387759689},
    year = {2008}
}

@article{RattoEtAl:2001,
    abstract = {A new approach is presented applicable in framework of model calibration to observed data. The approach consists of a combination of the Generalized Likelihood Uncertainty Estimation technique (GLUE) and Global Sensitivity Analysis (GSA). The method is based on multiple model evaluations. The GSA is a quantitative, model independent approach and is based on estimating the fractional contribution of each input factor to the variance of the model output, also accounting for interaction terms. In GLUE, the model runs are classified according to a likelihood measure, conditioning each run to observations. In calibration procedures, strong interaction is observed between model parameters, due to model over-parameterization. The use of likelihood measures allows an estimate of the posterior joint pdf of parameters. By performing a GSA to the likelihood measure, input factors mainly driving model runs with good fit to data are identified. Moreover GSA allows highlighting the basic features of the interaction structure. Any other tool subsequently adopted to represent in more detail the interaction structure, from correlation coefficients to Principal Component Analysis to Bayesian networks to tree-structured density estimation, confirms the general features identified by GSA.},
    author = {Ratto, M.},
    citeulike-article-id = {5984574},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0010-4655(01)00159-X},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0010-4655(01)00159-X},
    day = {15},
    doi = {10.1016/S0010-4655(01)00159-X},
    issn = {00104655},
    journal = {Computer Physics Communications},
    keywords = {calibration, sensitivity},
    month = {May},
    number = {3},
    pages = {212--224},
    posted-at = {2009-10-22 12:36:39},
    priority = {2},
    title = {Sensitivity analysis in model calibration: GSA-GLUE approach},
    url = {http://dx.doi.org/10.1016/S0010-4655(01)00159-X},
    volume = {136},
    year = {2001}
}

@article{Saltelli:2002,
    abstract = {We review briefly some examples that would support an extended role for quantitative sensitivity analysis in the context of model-based analysis (Section 1). We then review what features a quantitative sensitivity analysis needs to have to play such a role (Section 2). The methods that meet these requirements are described in Section 3; an example is provided in Section 4. Some pointers to further research are set out in Section 5.},
    author = {Saltelli, Andrea},
    citeulike-article-id = {5984568},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/0272-4332.00040},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/118950659/ABSTRACT},
    doi = {10.1111/0272-4332.00040},
    issn = {1539-6924},
    journal = {Risk Analysis},
    keywords = {sensitivity},
    number = {3},
    pages = {579--590},
    posted-at = {2009-10-22 12:33:36},
    priority = {0},
    title = {Sensitivity Analysis for Importance Assessment},
    url = {http://dx.doi.org/10.1111/0272-4332.00040},
    volume = {22},
    year = {2002}
}

@article{PappenbergerEtAl:2006,
    abstract = {A global sensitivity analysis with regional properties is introduced. This method is demonstrated on two synthetic and one hydraulic example. It can be shown that an uncertainty analysis based on one-dimensional scatter plots and correlation analyses such as the Spearman Rank Correlation coefficient can lead to misinterpretations of any model results. The method which has been proposed in this paper is based on multiple regression trees (so called Random Forests). The splits at each node of the regression tree are sampled from a probability distribution. Several criteria are enforced at each level of splitting to ensure positive information gain and also to distinguish between behavioural and non-behavioural model representations. The latter distinction is applied in the generalized likelihood uncertainty estimation (GLUE) and regional sensitivity analysis (RSA) framework to analyse model results and is used here to derive regression tree (model) structures. Two methods of sensitivity analysis are used: in the first method the total information gain achieved by each parameter is evaluated. In the second method parameters and parameter sets are permuted and an error rate computed. This error rate is compared to values without permutation. This latter method allows the evaluation of the sensitivity of parameter combinations and thus gives an insight into the structure of the response surface. The examples demonstrate the capability of this methodology and stress the importance of the application of sensitivity analysis.},
    author = {Pappenberger, F. and Iorgulescu, I. and Beven, K.},
    citeulike-article-id = {4005850},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2005.04.010},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815205000873},
    doi = {10.1016/j.envsoft.2005.04.010},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {sensitivity},
    month = {July},
    number = {7},
    pages = {976--990},
    posted-at = {2009-10-22 12:31:16},
    priority = {4},
    title = {Sensitivity analysis based on regional splits and regression trees (SARS-RT)},
    url = {http://dx.doi.org/10.1016/j.envsoft.2005.04.010},
    volume = {21},
    year = {2006}
}

@book{MorganHenrion:1990,
    author = {Morgan, M. G. and Henrion, M.},
    citeulike-article-id = {5983566},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0521427444},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0521427444},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0521427444},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0521427444},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0521427444/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521427444},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0521427444},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0521427444},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0521427444\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0521427444},
    day = {26},
    howpublished = {Paperback},
    isbn = {0521427444},
    keywords = {uncertainty},
    month = {June},
    posted-at = {2009-10-22 05:18:32},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Uncertainty: A Guide to Dealing with Uncertainty in Quantitative Risk and Policy Analysis},
    url = {http://www.worldcat.org/isbn/0521427444},
    year = {1990}
}

@article{FreyPatil:2002,
    abstract = {Identification and qualitative comparison of sensitivity analysis methods that have been used across various disciplines, and that merit consideration for application to food-safety risk assessment models, are presented in this article. Sensitivity analysis can help in identifying critical control points, prioritizing additional data collection or research, and verifying and validating a model. Ten sensitivity analysis methods, including four mathematical methods, five statistical methods, and one graphical method, are identified. The selected methods are compared on the basis of their applicability to different types of models, computational issues such as initial data requirement and complexity of their application, representation of the sensitivity, and the specific uses of these methods. Applications of these methods are illustrated with examples from various fields. No one method is clearly best for food-safety risk models. In general, use of two or more methods, preferably with dissimilar theoretical foundations, may be needed to increase confidence in the ranking of key inputs.},
    address = {Department of Civil Engineering, North Carolina State University, Raleigh, NC.;  Department of Civil Engineering, North Carolina State University, Raleigh, NC. Please note that the work described in this article was performed at NCSU; the author is now at Research Triangle Institute, Research Triangle Park, NC.},
    author = {Frey, H. Christopher and Patil, Sumeet R.},
    citeulike-article-id = {5983546},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/0272-4332.00039},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/118950658/ABSTRACT},
    doi = {10.1111/0272-4332.00039},
    issn = {1539-6924},
    journal = {Risk Analysis},
    keywords = {sensitivity},
    number = {3},
    pages = {553--578},
    posted-at = {2009-10-22 05:03:01},
    priority = {0},
    title = {Identification and Review of Sensitivity Analysis Methods},
    url = {http://dx.doi.org/10.1111/0272-4332.00039},
    volume = {22},
    year = {2002}
}

@book{BreimanEtAl:1984,
    abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
    author = {Breiman, Leo and Friedman, Jerome and Stone, Charles J. and Olshen, R. A.},
    citeulike-article-id = {801011},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&\#38;path=ASIN/0412048418},
    citeulike-linkout-1 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0412048418},
    citeulike-linkout-10 = {http://www.librarything.com/isbn/0412048418},
    citeulike-linkout-2 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0412048418},
    citeulike-linkout-3 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0412048418},
    citeulike-linkout-4 = {http://www.amazon.jp/exec/obidos/ASIN/0412048418},
    citeulike-linkout-5 = {http://www.amazon.co.uk/exec/obidos/ASIN/0412048418/citeulike00-21},
    citeulike-linkout-6 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0412048418},
    citeulike-linkout-7 = {http://www.worldcat.org/isbn/0412048418},
    citeulike-linkout-8 = {http://books.google.com/books?vid=ISBN0412048418},
    citeulike-linkout-9 = {http://www.amazon.com/gp/search?keywords=0412048418\&index=books\&linkCode=qs},
    day = {01},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0412048418},
    keywords = {statistics},
    month = {January},
    posted-at = {2009-10-19 04:59:57},
    priority = {1},
    publisher = {Chapman \& Hall/CRC},
    title = {Classification and Regression Trees},
    url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0412048418},
    year = {1984}
}

@article{Rykiel:1996,
    abstract = {The ecological literature reveals considerable confusion about the meaning of validation in the context of simulation models. The confusion arises as much from semantic and philosophical considerations as from the selection of validation procedures. Validation is not a procedure for testing scientific theory or for certifying the 'truth' of current scientific understanding, nor is it a required activity of every modelling project. Validation means that a model is acceptable for its intended use because it meets specified performance requirements. Before validation is undertaken, (1) the purpose of the model, (2) the performance criteria, and (3) the model context must be specified. The validation process can be decomposed into several components: (1) operation, (2) theory, and (3) data. Important concepts needed to understand the model evaluation process are verification, calibration, validation, credibility, and qualification. These terms are defined in a limited technical sense applicable to the evaluation of simulation models, and not as general philosophical concepts. Different tests and standards are applied to the operational, theoretical, and data components. The operational and data components can be validated; the theoretical component cannot. The most common problem with ecological and environmental models is failure to state what the validation criteria are. Criteria must be explicitly stated because there are no universal standards for selecting what test procedures or criteria to use for validation. A test based on comparison of simulated versus observed data is generally included whenever possible. Because the objective and subjective components of validation are not mutually exclusive, disagreements over the meaning of validation can only be resolved by establishing a convention.},
    author = {Rykiel, E.},
    citeulike-article-id = {2669753},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0304-3800(95)00152-2},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0304-3800(95)00152-2},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6VBS-3VWK7V1-7/1/4ba15c37c80a1657fe1ff08aef05bc60},
    day = {01},
    doi = {10.1016/0304-3800(95)00152-2},
    issn = {03043800},
    journal = {Ecological Modelling},
    keywords = {uncertainty},
    month = {November},
    number = {3},
    pages = {229--244},
    posted-at = {2009-10-19 04:14:06},
    priority = {0},
    title = {Testing ecological models: the meaning of validation},
    url = {http://dx.doi.org/10.1016/0304-3800(95)00152-2},
    volume = {90},
    year = {1996}
}

@article{ReichertBorsuk:2005,
    abstract = {The uncertainty in the predictions of models for the behaviour of environmental systems is usually very large. In many cases the widths of the predictive probability distributions for outcomes of interest are significantly larger than the differences between the expected values of the outcomes across different policy alternatives. This seems to lead to a serious problem for model-based decision support because policy actions appear to have an insignificant effect on variables describing their consequences, relative to the predictive uncertainty. However, in some cases it is evident that some of the alternatives at least lead to changes in the desired direction. A formal analysis of this situation is made based on the dependence structure of the variables of interest across different policy alternatives. This analysis leads to the conclusion that the uncertainty in the difference of model predictions corresponding to different policies may be significantly smaller than the uncertainty in the predictions themselves. The knowledge about the uncertainty in this difference may be relevant information for the decision maker in addition to the information usually provided. The conceptual development is supplemented with a presentation of convenient methods for practical implementation. These are illustrated with a simple, didactical model for the effect of phosphorus discharge reduction alternatives on phosphorus loading to a lake.},
    author = {Reichert, P. and Borsuk, M.},
    citeulike-article-id = {5968646},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2004.10.005},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815204002373},
    doi = {10.1016/j.envsoft.2004.10.005},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {uncertainty},
    month = {August},
    number = {8},
    pages = {991--1001},
    posted-at = {2009-10-19 00:07:35},
    priority = {0},
    title = {Does high forecast uncertainty preclude effective decision support?},
    url = {http://dx.doi.org/10.1016/j.envsoft.2004.10.005},
    volume = {20},
    year = {2005}
}

@article{RavalicoEtAl:2009,
    abstract = {Integrated Assessment Modelling (IAM) incorporates knowledge from different disciplines to provide an overarching assessment of the impact of different management decisions. The complex nature of these models, which often include non-linearities and feedback loops, requires special attention for sensitivity analysis. This is especially true when the models are used to form the basis of management decisions, where it is important to assess how sensitive the decisions being made are to changes in model parameters. This research proposes an extension to the Management Option Rank Equivalence (MORE) method of sensitivity analysis; a new method of sensitivity analysis developed specifically for use in IAM and decision-making. The extension proposes using a multi-objective Pareto optimal search to locate minimum combined parameter changes that result in a change in the preferred management option. It is demonstrated through a case study of the Namoi River, where results show that the extension to MORE is able to provide sensitivity information for individual parameters that takes into account simultaneous variations in all parameters. Furthermore, the increased sensitivities to individual parameters that are discovered when joint parameter variation is taken into account shows the importance of ensuring that any sensitivity analysis accounts for these changes.},
    author = {Ravalico, Jakin K. and Maier, Holger R. and Dandy, Graeme C.},
    citeulike-article-id = {5968642},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ress.2009.01.009},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0951832009000234},
    doi = {10.1016/j.ress.2009.01.009},
    issn = {09518320},
    journal = {Reliability Engineering \& System Safety},
    keywords = {sensitivity},
    month = {July},
    number = {7},
    pages = {1229--1237},
    posted-at = {2009-10-19 00:04:02},
    priority = {3},
    title = {Sensitivity analysis for decision-making using the MORE method—A Pareto approach},
    url = {http://dx.doi.org/10.1016/j.ress.2009.01.009},
    volume = {94},
    year = {2009}
}

@article{NguyenDeKok:2007,
    abstract = {Systematic testing of integrated systems models is extremely important but its difficulty is widely underestimated. The inherent complexity of the integrated systems models, the philosophical debate about the model validity and validation, the uncertainty in model inputs, parameters and future context and the scarcity of field data complicate model validation. This calls for a validation framework and procedures which can identify the strengths and weaknesses of the model with the available data from observations, the literature and experts' opinions. This paper presents such a framework and the respective procedure. Three tests, namely, Parameter-Verification, Behaviour-Anomaly and Policy-Sensitivity are selected to test a Rapid assessment Model for Coastal-zone Management (RaMCo). The Morris sensitivity analysis, a simple expert elicitation technique and Monte Carlo uncertainty analysis are used to facilitate these three tests. The usefulness of the procedure is demonstrated for two examples.},
    author = {Nguyen, T. and de Kok, J.},
    citeulike-article-id = {4005819},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2006.08.008},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815206002064},
    doi = {10.1016/j.envsoft.2006.08.008},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {sensitivity},
    month = {November},
    number = {11},
    pages = {1572--1587},
    posted-at = {2009-10-16 02:09:41},
    priority = {2},
    title = {Systematic testing of an integrated systems model for coastal zone management using sensitivity and uncertainty analyses},
    url = {http://dx.doi.org/10.1016/j.envsoft.2006.08.008},
    volume = {22},
    year = {2007}
}

@article{ForresterSenge:1980,
    author = {Forrester, J. W. and Senge, P. M.},
    citeulike-article-id = {5948119},
    journal = {TIMS studies in the management sciences},
    pages = {209--228},
    posted-at = {2009-10-16 02:06:37},
    priority = {2},
    title = {Test for Building Confidence in System Dynamics Models},
    volume = {14},
    year = {1980}
}

@article{Morris:1991,
    abstract = {A computational model is a representation of some physical or other system of interest, first expressed mathematically and then implemented in the form of a computer program; it may be viewed as a function of inputs that, when evaluated, produces outputs. Motivation for this article comes from computational models that are deterministic, complicated enough to make classical mathematical analysis impractical and that have a moderate-to-large number of inputs. The problem of designing computational experiments to determine which inputs have important effects on an output is considered. The proposed experimental plans are composed of individually randomized one-factor-at-a-time designs, and data analysis is based on the resulting random sample of observed elementary effects, those changes in an output due solely to changes in a particular input. Advantages of this approach include a lack of reliance on assumptions of relative sparsity of important inputs, monotonicity of outputs with respect to inputs, or adequacy of a low-order polynomial as an approximation to the computational model.},
    author = {Morris, Max D.},
    citeulike-article-id = {5946806},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/1269043},
    citeulike-linkout-1 = {http://www.jstor.org/stable/1269043},
    doi = {10.2307/1269043},
    issn = {00401706},
    journal = {Technometrics},
    keywords = {sensitivity},
    number = {2},
    pages = {161--174},
    posted-at = {2009-10-16 00:21:20},
    priority = {2},
    publisher = {American Statistical Association and American Society for Quality},
    title = {Factorial Sampling Plans for Preliminary Computational Experiments},
    url = {http://dx.doi.org/10.2307/1269043},
    volume = {33},
    year = {1991}
}

@article{HothornEtAl:2006b,
    abstract = {We propose a unified and flexible framework for ensemble learning in the presence of censoring. For right-censored data, we introduce a random forest algorithm and a generic gradient boosting algorithm for the construction of prognostic and diagnostic models. The methodology is utilized for predicting the survival time of patients suffering from acute myeloid leukemia based on clinical and genetic covariates. Furthermore, we compare the diagnostic capabilities of the proposed censored data random forest and boosting methods, applied to the recurrence-free survival time of node-positive breast cancer patients, with previously published findings. 10.1093/biostatistics/kxj011},
    author = {Hothorn, Torsten and Buhlmann, Peter and Dudoit, Sandrine and Molinaro, Annette and Van Der Laan, Mark J.},
    citeulike-article-id = {710957},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biostatistics/kxj011},
    citeulike-linkout-1 = {http://biostatistics.oxfordjournals.org/content/7/3/355.abstract},
    citeulike-linkout-2 = {http://biostatistics.oxfordjournals.org/content/7/3/355.full.pdf},
    citeulike-linkout-3 = {http://biostatistics.oxfordjournals.org/cgi/content/abstract/7/3/355},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/16344280},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=16344280},
    day = {1},
    doi = {10.1093/biostatistics/kxj011},
    issn = {1465-4644},
    journal = {Biostat},
    keywords = {statistics},
    month = {July},
    number = {3},
    pages = {355--373},
    posted-at = {2009-10-12 04:54:05},
    priority = {1},
    publisher = {Oxford University Press},
    title = {Survival ensembles},
    url = {http://dx.doi.org/10.1093/biostatistics/kxj011},
    volume = {7},
    year = {2006}
}

@article{StroblEtAl:2007,
    abstract = {BACKGROUND:Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories.RESULTS:Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand.CONCLUSION:We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research.},
    author = {Strobl, Carolin and Boulesteix, Anne L. and Zeileis, Achim and Hothorn, Torsten},
    citeulike-article-id = {1069581},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2105-8-25},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/17254353},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=17254353},
    day = {25},
    doi = {10.1186/1471-2105-8-25},
    issn = {1471-2105},
    journal = {BMC Bioinformatics},
    keywords = {importance, statistics},
    month = {January},
    number = {1},
    pages = {25+},
    posted-at = {2009-10-12 04:47:47},
    priority = {2},
    title = {Bias in random forest variable importance measures: Illustrations, sources and a solution},
    url = {http://dx.doi.org/10.1186/1471-2105-8-25},
    volume = {8},
    year = {2007}
}

@article{HothornEtAl:2006,
    author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
    citeulike-article-id = {852271},
    citeulike-linkout-0 = {http://dx.doi.org/10.1198/106186006X133933},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/asa/jcgs/2006/00000015/00000003/art00009},
    doi = {10.1198/106186006X133933},
    issn = {1061-8600},
    journal = {Journal of Computational and Graphical Statistics},
    keywords = {software, statistics},
    month = {September},
    number = {3},
    pages = {651--674},
    posted-at = {2009-10-12 04:23:52},
    priority = {2},
    publisher = {American Statistical Association},
    title = {Unbiased Recursive Partitioning},
    url = {http://dx.doi.org/10.1198/106186006X133933},
    volume = {15},
    year = {2006}
}

@book{SaltelliEtAl:2000,
    author = {Saltelli, A. and Chan, K. and Scott},
    citeulike-article-id = {5923475},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471998923},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0471998923},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/43552650},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0471998923},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0471998923},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471998923/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471998923},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0471998923},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0471998923},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0471998923\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0471998923},
    day = {15},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0471998923},
    keywords = {sensitivity},
    month = {October},
    posted-at = {2009-10-12 04:13:33},
    priority = {2},
    publisher = {Wiley},
    series = {Wiley series in probability and statistics},
    title = {Sensitivity analysis},
    url = {http://www.worldcat.org/isbn/0471998923},
    year = {2000}
}

@article{Breiman:2001,
    abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
    author = {Breiman, Leo},
    citeulike-article-id = {1121661},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=570182},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/A:1010933404324},
    citeulike-linkout-2 = {http://www.springerlink.com/content/u0p06167n6173512},
    day = {1},
    doi = {10.1023/A:1010933404324},
    issn = {08856125},
    journal = {Machine Learning},
    keywords = {statistics},
    month = {October},
    number = {1},
    pages = {5--32},
    posted-at = {2009-10-12 04:10:12},
    priority = {2},
    title = {Random Forests},
    url = {http://dx.doi.org/10.1023/A:1010933404324},
    volume = {45},
    year = {2001}
}

@article{StroblEtAl:2008,
    abstract = {BACKGROUND:Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables.RESULTS:We identify two mechanisms responsible for this finding: (i) A preference for the selection of correlated predictors in the tree building process and (ii) an additional advantage for correlated predictor variables induced by the unconditional permutation scheme that is employed in the computation of the variable importance measure. Based on these considerations we develop a new, conditional permutation scheme for the computation of the variable importance measure.CONCLUSION:The resulting conditional variable importance reflects the true impact of each predictor variable more reliably than the original marginal approach.},
    author = {Strobl, Carolin and Boulesteix, Anne L. and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
    citeulike-article-id = {2996042},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2105-9-307},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/18620558},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=18620558},
    day = {11},
    doi = {10.1186/1471-2105-9-307},
    issn = {1471-2105},
    journal = {BMC Bioinformatics},
    keywords = {importance},
    month = {July},
    number = {1},
    pages = {307+},
    posted-at = {2009-10-12 01:59:46},
    priority = {2},
    title = {Conditional variable importance for random forests},
    url = {http://dx.doi.org/10.1186/1471-2105-9-307},
    volume = {9},
    year = {2008}
}

@article{Risbey:2007,
    abstract = {Abstract\&nbsp;\&nbsp;Subjective elements are an inevitable component of scientific advice on climate policies. Good practice warrants that the level of assumption underlying subjective elements be parsimonious, that their effects on policy decisions be identified, and that policy relevant variables be communicated with appropriate levels of precision. In the case of climate sensitivity, the level of precision is intrinsically difficult to quantify. There is no 'true' value of climate sensitivity to be discovered. Rather, best practice consists of the application of multiple methods to estimate the quantity. Best practice provides confidence that some values of climate sensitivity are more likely than others. This lends support to the notion of weighting climate sensitivity values, though the appropriate precision appears to be less than that implied by use of a probability density function (pdf) and greater than that implied by use of a simple range. Use of both a pdf and a range in this case can provide information about likely outcomes and possible extremes.},
    author = {Risbey, James},
    citeulike-article-id = {5785201},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10584-007-9314-8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/2j1r5426060636j8},
    day = {1},
    doi = {10.1007/s10584-007-9314-8},
    journal = {Climatic Change},
    keywords = {uncertainty},
    month = {November},
    number = {1},
    pages = {11--17},
    posted-at = {2009-09-15 07:28:35},
    priority = {2},
    title = {Subjective elements in climate policy advice},
    url = {http://dx.doi.org/10.1007/s10584-007-9314-8},
    volume = {85},
    year = {2007}
}

@article{DessaiHulme:2004,
    abstract = {Estimating the likelihood of future climate change has become a priority objective within the research community. This is the case because of the advancement of science, because of user demand and because of the central role played by climate prediction in guiding adaptation policy. But are probabilities what climate policy really needs\&\#63; This article reviews three key questions: (1) Why might we (not) need probabilities of climate change\&\#63; (2) What are the problems in estimating probabilities\&\#63; (3) How are researchers estimating probabilities\&\#63; These questions are analysed within the context of adaptation to climate change. Overall, we conclude that the jury is still out on whether probabilities are useful for climate adaptation policy. The answer is highly context dependent and thus is a function of the goals and motivation of the policy analysis, the unit of analysis, timescale and the training of the analyst. Probability assessment in the context of climate change is always subjective, conditional and provisional. There are various problems in estimating the probability of future climate change, but reflexive human behaviour (i.e. actions explicitly influenced by information) is largely intractable in the context of prediction. Nonetheless, there is considerable scope to develop novel methodologies that combine conditional probabilities with scenarios and which are relevant for climate decision-making.},
    author = {Dessai, Suraje and Hulme, Mike},
    citeulike-article-id = {5785198},
    citeulike-linkout-0 = {http://www.ingentaconnect.com/content/earthscan/cpol/2004/00000004/00000002/art00002},
    issn = {1469-3062},
    journal = {Climate Policy},
    keywords = {uncertainty},
    pages = {107--128},
    posted-at = {2009-09-15 07:26:35},
    priority = {2},
    publisher = {Earthscan},
    title = {Does climate adaptation policy need probabilities},
    url = {http://www.ingentaconnect.com/content/earthscan/cpol/2004/00000004/00000002/art00002},
    year = {2004}
}

@article{SchoupsEtAl:2008,
    abstract = {A common concern in hydrologic modeling is overparameterization of complex models given limited and noisy data. This leads
                     to problems of parameter nonuniqueness and equifinality, which may negatively affect prediction uncertainties. A systematic
                     way of controlling model complexity is therefore needed. We compare three model complexity control methods for hydrologic
                     prediction, namely, cross validation (CV), Akaike's information criterion (AIC), and structural risk minimization (SRM). Results
                     show that simulation of water flow using non-physically-based models (polynomials in this case) leads to increasingly better
                     calibration fits as the model complexity (polynomial order) increases. However, prediction uncertainty worsens for complex
                     non-physically-based models because of overfitting of noisy data. Incorporation of physically based constraints into the model
                     (e.g., storage-discharge relationship) effectively bounds prediction uncertainty, even as the number of parameters increases.
                     The conclusion is that overparameterization and equifinality do not lead to a continued increase in prediction uncertainty,
                     as long as models are constrained by such physical principles. Complexity control of hydrologic models reduces parameter equifinality
                     and identifies the simplest model that adequately explains the data, thereby providing a means of hydrologic generalization
                     and classification. SRM is a promising technique for this purpose, as it (1) provides analytic upper bounds on prediction
                     uncertainty, hence avoiding the computational burden of CV, and (2) extends the applicability of classic methods such as AIC
                     to finite data. The main hurdle in applying SRM is the need for an a priori estimation of the complexity of the hydrologic
                     model, as measured by its Vapnik-Chernovenkis (VC) dimension. Further research is needed in this area.
                  },
    author = {Schoups, G. and van de Giesen, N. C. and Savenije, H. H. G.},
    citeulike-article-id = {5779852},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2008/2008WR006836.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2008WR006836},
    day = {28},
    doi = {10.1029/2008WR006836},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {topdown},
    month = {August},
    number = {null},
    pages = {W00B03+},
    posted-at = {2009-09-14 07:16:22},
    priority = {2},
    title = {Model complexity control for hydrologic prediction},
    url = {http://dx.doi.org/10.1029/2008WR006836},
    volume = {44},
    year = {2008}
}

@article{GotzingerBardossy:2008,
    abstract = {Because of the necessary simplification of the complex natural processes and the limited availability of observations, model
                     simulations are always uncertain and this uncertainty should be quantified. In this contribution, the model error is quantified
                     using a combined procedure. For the uncertainty of discharge due to meteorological input, a stochastic simulation method is
                     used. To quantify the effect of process representation and parameterization, a sensitivity analysis is carried out. It is
                     assumed that the model error due to process uncertainty is proportional to the sensitivity. The final model error variance
                     can thus be calculated from the stochastic errors and the process sensitivities. The coefficients used for the quantification
                     are estimated simultaneously with the model parameters. The methodology presented produces error series that are normally
                     distributed and that represent the varying importance of different processes in time. This uncertainty time series can be
                     used as a weighting factor to normalize the model residuals during calibration so that the assumptions of least squares optimization
                     are fulfilled. Calibration and uncertainty estimation are demonstrated with an example application of a distributed Hydrological
                     Bureau Waterbalance (HBV) model of three watersheds in the Neckar basin in southwest Germany. The model residual distributions
                     are presented and compared to a standard calibration method. Further, it is shown that the new methodology leads to more realistic
                     confidence intervals for model simulations. Although applied to the HBV model as an example, the method is general and can
                     be applied to any model and also in conjunction with other uncertainty estimation techniques.
                  },
    author = {G\&\#246;tzinger, Jens and B\&\#225;rdossy, Andr\&\#225;s},
    citeulike-article-id = {5779828},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2008/2007WR006691.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2007WR006691},
    day = {8},
    doi = {10.1029/2007WR006691},
    issn = {0043-1397},
    journal = {Water Resources Research},
    month = {November},
    number = {null},
    pages = {W00B07+},
    posted-at = {2009-09-14 07:01:04},
    priority = {4},
    title = {Generic error model for calibration and uncertainty estimation of hydrological models},
    url = {http://dx.doi.org/10.1029/2007WR006691},
    volume = {44},
    year = {2008}
}

@article{GuptaEtAl:2008,
    author = {Gupta, Hoshin V. and Wagener, Thorsten and Liu, Yuqiong},
    citeulike-article-id = {5779794},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hyp.6989},
    day = {30},
    doi = {10.1002/hyp.6989},
    issn = {08856087},
    journal = {Hydrological Processes},
    keywords = {grand, uncertainty},
    month = {August},
    number = {18},
    pages = {3802--3813},
    posted-at = {2009-09-14 06:16:26},
    priority = {4},
    title = {Reconciling theory with observations: elements of a diagnostic approach to model evaluation},
    url = {http://dx.doi.org/10.1002/hyp.6989},
    volume = {22},
    year = {2008}
}

@article{GelmanRubin:1992,
    author = {Gelman, Andrew and Rubin, Donald B.},
    citeulike-article-id = {5779654},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/ss/1177011136},
    doi = {10.1214/ss/1177011136},
    issn = {0883-4237},
    journal = {Statistical Science},
    keywords = {mcmc},
    month = {November},
    number = {4},
    pages = {457--472},
    posted-at = {2009-09-14 00:52:52},
    priority = {1},
    title = {Inference from Iterative Simulation Using Multiple Sequences},
    url = {http://dx.doi.org/10.1214/ss/1177011136},
    volume = {7},
    year = {1992}
}

@article{VrugtEtAl:2003,
    abstract = {Markov Chain Monte Carlo (MCMC) methods have become increasingly popular for estimating the posterior probability distribution
                     of parameters in hydrologic models. However, MCMC methods require the a priori definition of a proposal or sampling distribution,
                     which determines the explorative capabilities and efficiency of the sampler and therefore the statistical properties of the
                     Markov Chain and its rate of convergence. In this paper we present an MCMC sampler entitled the Shuffled Complex Evolution
                     Metropolis algorithm (SCEM-UA), which is well suited to infer the posterior distribution of hydrologic model parameters. The
                     SCEM-UA algorithm is a modified version of the original SCE-UA global optimization algorithm developed by 
                     
Duan et al. [1992]
                     . The SCEM-UA algorithm operates by merging the strengths of the Metropolis algorithm, controlled random search, competitive
                     evolution, and complex shuffling in order to continuously update the proposal distribution and evolve the sampler to the posterior
                     target distribution. Three case studies demonstrate that the adaptive capability of the SCEM-UA algorithm significantly reduces
                     the number of model simulations needed to infer the posterior distribution of the parameters when compared with the traditional
                     Metropolis-Hastings samplers.
                  },
    author = {Vrugt, Jasper A. and Gupta, Hoshin V. and Bouten, Willem and Sorooshian, Soroosh},
    citeulike-article-id = {5772052},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2003/2002WR001642.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2002WR001642},
    day = {1},
    doi = {10.1029/2002WR001642},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {mcmc},
    month = {August},
    number = {8},
    pages = {1201+},
    posted-at = {2009-09-11 05:52:18},
    priority = {2},
    title = {A Shuffled Complex Evolution Metropolis algorithm for optimization and uncertainty assessment of hydrologic model parameters},
    url = {http://dx.doi.org/10.1029/2002WR001642},
    volume = {39},
    year = {2003}
}

@article{PappenbergerBeven:2006,
    abstract = {Uncertainty analysis of models has received increasing attention over the last two decades in water resources research. However,
                     a significant part of the community is still reluctant to embrace the estimation of uncertainty in hydrological and hydraulic
                     modeling. In this paper, we summarize and explore seven common arguments: uncertainty analysis is not necessary given physically
                     realistic models; uncertainty analysis cannot be used in hydrological and hydraulic hypothesis testing; uncertainty (probability)
                     distributions cannot be understood by policy makers and the public; uncertainty analysis cannot be incorporated into the decision-making
                     process; uncertainty analysis is too subjective; uncertainty analysis is too difficult to perform; uncertainty does not really
                     matter in making the final decision. We will argue that none of the arguments against uncertainty analysis rehearsed are,
                     in the end, tenable. Moreover, we suggest that one reason why the application of uncertainty analysis is not normal and expected
                     part of modeling practice is that mature guidance on methods and applications does not exist. The paper concludes with suggesting
                     that a Code of Practice is needed as a way of formalizing such guidance.
                  },
    author = {Pappenberger, F. and Beven, K. J.},
    citeulike-article-id = {5764259},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2006/2005WR004820.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2005WR004820},
    day = {16},
    doi = {10.1029/2005WR004820},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {grand, uncertainty},
    month = {May},
    number = {5},
    pages = {W05302+},
    posted-at = {2009-09-10 00:21:48},
    priority = {3},
    title = {Ignorance is bliss: Or seven reasons not to use uncertainty analysis},
    url = {http://dx.doi.org/10.1029/2005WR004820},
    volume = {42},
    year = {2006}
}

@article{ThyerEtAl:2009,
    abstract = {The lack of a robust framework for quantifying the parametric and predictive uncertainty of conceptual rainfall‐runoff (CRR)
                     models remains a key challenge in hydrology. The Bayesian total error analysis (BATEA) methodology provides a comprehensive
                     framework to hypothesize, infer, and evaluate probability models describing input, output, and model structural error. This
                     paper assesses the ability of BATEA and standard calibration approaches (standard least squares (SLS) and weighted least squares
                     (WLS)) to address two key requirements of uncertainty assessment: (1) reliable quantification of predictive uncertainty and
                     (2) reliable estimation of parameter uncertainty. The case study presents a challenging calibration of the lumped GR4J model
                     to a catchment with ephemeral responses and large rainfall gradients. Postcalibration diagnostics, including checks of predictive
                     distributions using quantile‐quantile analysis, suggest that while still far from perfect, BATEA satisfied its assumed probability
                     models better than SLS and WLS. In addition, WLS/SLS parameter estimates were highly dependent on the selected rain gauge
                     and calibration period. This will obscure potential relationships between CRR parameters and catchment attributes and prevent
                     the development of meaningful regional relationships. Conversely, BATEA provided consistent, albeit more uncertain, parameter
                     estimates and thus overcomes one of the obstacles to parameter regionalization. However, significant departures from the calibration
                     assumptions remained even in BATEA, e.g., systematic overestimation of predictive uncertainty, especially in validation. This
                     is likely due to the inferred rainfall errors compensating for simplified treatment of model structural error.
                  },
    author = {Thyer, Mark and Renard, Benjamin and Kavetski, Dmitri and Kuczera, George and Franks, Stewart W. and Srikanthan, Sri},
    citeulike-article-id = {5737942},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2009/2008WR006825.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2008WR006825},
    day = {1},
    doi = {10.1029/2008WR006825},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {uncertainty},
    month = {April},
    number = {null},
    pages = {W00B14+},
    posted-at = {2009-09-08 01:03:39},
    priority = {5},
    title = {Critical evaluation of parameter consistency and predictive uncertainty in hydrological modeling: A case study using Bayesian total error analysis},
    url = {http://dx.doi.org/10.1029/2008WR006825},
    volume = {45},
    year = {2009}
}

@article{BlasoneEtAl:2008,
    abstract = {In the last few decades hydrologists have made tremendous progress in using dynamic simulation models for the analysis and understanding of hydrologic systems. However, predictions with these models are often deterministic and as such they focus on the most probable forecast, without an explicit estimate of the associated uncertainty. This uncertainty arises from incomplete process representation, uncertainty in initial conditions, input, output and parameter error. The generalized likelihood uncertainty estimation (GLUE) framework was one of the first attempts to represent prediction uncertainty within the context of Monte Carlo (MC) analysis coupled with Bayesian estimation and propagation of uncertainty. Because of its flexibility, ease of implementation and its suitability for parallel implementation on distributed computer systems, the GLUE method has been used in a wide variety of applications. However, the MC based sampling strategy of the prior parameter space typically utilized in GLUE is not particularly efficient in finding behavioral simulations. This becomes especially problematic for high-dimensional parameter estimation problems, and in the case of complex simulation models that require significant computational time to run and produce the desired output. In this paper we improve the computational efficiency of GLUE by sampling the prior parameter space using an adaptive Markov Chain Monte Carlo scheme (the Shuffled Complex Evolution Metropolis (SCEM-UA) algorithm). Moreover, we propose an alternative strategy to determine the value of the cutoff threshold based on the appropriate coverage of the resulting uncertainty bounds. We demonstrate the superiority of this revised GLUE method with three different conceptual watershed models of increasing complexity, using both synthetic and real-world streamflow data from two catchments with different hydrologic regimes.},
    author = {Blasone, R. and Vrugt, J. and Madsen, H. and Rosbjerg, D. and Robinson, B. and Zyvoloski, G.},
    citeulike-article-id = {2910478},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.advwatres.2007.12.003},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0309170807001856},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6VCF-4RTCV95-1/1/db3254eb4b824f1e84ce412fadc76495},
    doi = {10.1016/j.advwatres.2007.12.003},
    issn = {03091708},
    journal = {Advances in Water Resources},
    keywords = {uncertainty},
    month = {April},
    number = {4},
    pages = {630--648},
    posted-at = {2009-09-06 15:03:23},
    priority = {4},
    title = {Generalized likelihood uncertainty estimation (GLUE) using adaptive Markov Chain Monte Carlo sampling},
    url = {http://dx.doi.org/10.1016/j.advwatres.2007.12.003},
    volume = {31},
    year = {2008}
}

@article{VrugtRobinson:2007,
    abstract = {Predictive uncertainty analysis in hydrologic modeling has become an active area of research, the goal being to generate meaningful
                     error bounds on model predictions. State-space filtering methods, such as the ensemble Kalman filter (EnKF), have shown the
                     most flexibility to integrate all sources of uncertainty. However, predictive uncertainty analyses are typically carried out
                     using a single conceptual mathematical model of the hydrologic system, rejecting a priori valid alternative plausible models
                     and possibly underestimating uncertainty in the model itself. Methods based on Bayesian model averaging (BMA) have also been
                     proposed in the statistical and meteorological literature as a means to account explicitly for conceptual model uncertainty.
                     The present study compares the performance and applicability of the EnKF and BMA for probabilistic ensemble streamflow forecasting,
                     an application for which a robust comparison of the predictive skills of these approaches can be conducted. The results suggest
                     that for the watershed under consideration, BMA cannot achieve a performance matching that of the EnKF method.
                  },
    author = {Vrugt, Jasper A. and Robinson, Bruce A.},
    citeulike-article-id = {5727673},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2007/2005WR004838.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2005WR004838},
    day = {17},
    doi = {10.1029/2005WR004838},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {statistics, timeseries, uncertainty},
    month = {January},
    number = {1},
    pages = {W01411+},
    posted-at = {2009-09-06 12:30:10},
    priority = {4},
    title = {Treatment of uncertainty using ensemble methods: Comparison of sequential data assimilation and Bayesian model averaging},
    url = {http://dx.doi.org/10.1029/2005WR004838},
    volume = {43},
    year = {2007}
}

@article{HaarioEtAl:2006,
    abstract = {Abstract  We propose to combine two quite powerful ideas that have recently appeared in the Markov chain Monte Carlo literature: adaptive Metropolis samplers and delayed rejection. The ergodicity of the resulting non-Markovian sampler is proved, and the efficiency of the combination is demonstrated with various examples. We present situations where the combination outperforms the original methods: adaptation clearly enhances efficiency of the delayed rejection algorithm in cases where good proposal distributions are not available. Similarly, delayed rejection provides a systematic remedy when the adaptation process has a slow start.},
    author = {Haario, Heikki and Laine, Marko and Mira, Antonietta and Saksman, Eero},
    citeulike-article-id = {954224},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11222-006-9438-0},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/stco/2006/00000016/00000004/00009438},
    citeulike-linkout-2 = {http://www.springerlink.com/content/e1t2t818r3129t80},
    day = {1},
    doi = {10.1007/s11222-006-9438-0},
    issn = {0960-3174},
    journal = {Statistics and Computing},
    keywords = {calibration},
    month = {December},
    number = {4},
    pages = {339--354},
    posted-at = {2009-09-04 05:39:41},
    priority = {2},
    publisher = {Springer},
    title = {DRAM: Efficient adaptive MCMC},
    url = {http://dx.doi.org/10.1007/s11222-006-9438-0},
    volume = {16},
    year = {2006}
}

@article{VrugtEtAl:2008:Inputs,
    abstract = {There is increasing consensus in the hydrologic literature that an appropriate framework for streamflow forecasting and simulation
                        should include explicit recognition of forcing and parameter and model structural error. This paper presents a novel Markov
                        chain Monte Carlo (MCMC) sampler, entitled differential evolution adaptive Metropolis (DREAM), that is especially designed
                        to efficiently estimate the posterior probability density function of hydrologic model parameters in complex, high-dimensional
                        sampling problems. This MCMC scheme adaptively updates the scale and orientation of the proposal distribution during sampling
                        and maintains detailed balance and ergodicity. It is then demonstrated how DREAM can be used to analyze forcing data error
                        during watershed model calibration using a five-parameter rainfall-runoff model with streamflow data from two different catchments.
                        Explicit treatment of precipitation error during hydrologic model calibration not only results in prediction uncertainty bounds
                        that are more appropriate but also significantly alters the posterior distribution of the watershed model parameters. This
                        has significant implications for regionalization studies. The approach also provides important new ways to estimate areal
                        average watershed precipitation, information that is of utmost importance for testing hydrologic theory, diagnosing structural
                        errors in models, and appropriately benchmarking rainfall measurement devices.
                     },
    author = {Vrugt, Jasper A. and ter Braak, Cajo J. F. and Clark, Martyn P. and Hyman, James M. and Robinson, Bruce A.},
    citeulike-article-id = {4233477},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2008/2007WR006720.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2007WR006720},
    day = {17},
    doi = {10.1029/2007WR006720},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {grand, uncertainty},
    month = {December},
    number = {12},
    pages = {W00B09+},
    posted-at = {2009-09-04 02:41:33},
    priority = {5},
    title = {Treatment of input uncertainty in hydrologic modeling: Doing hydrology backward with Markov chain Monte Carlo simulation},
    url = {http://dx.doi.org/10.1029/2007WR006720},
    volume = {44},
    year = {2008}
}

@article{FarmerEtAl:2003,
    abstract = {Observed differences between water balance for temperate and semiarid catchments can be attributed to variability in the primary
                     controls of the soil profile (soil water storage capacity and permeability), vegetation (surface coverage and water use efficiency),
                     and climate (rainfall and potential evaporation). Motivated by the downward development methodology mooted by 
                     Klemes [1983]
                     , this paper explores the underlying climate and landscape interactions that cause differences in water balance between a
                     number of temperate and semiarid benchmark catchments around Australia. A systematic parsimonious analysis based around a
                     simple water balance model whose parameters are estimated from available data is used to observe and interpret signatures
                     of annual, intra-annual, and daily water balance behavior and variability. The essence of the downward analysis is that model
                     complexity evolves from the simplest form to its final quasi-distributed framework with multiple storages and process interactions
                     in response to inadequacies in signature prediction. Consequently, each step in the process develops insight into local climate
                     and landscape influences and sensitivity to their temporal and spatial variabilities. The results affirm that the relative
                     influence of climate and landscape properties upon catchment response is manifested in a systematic transformation of process
                     sensitivity with increasing timescales (annual, monthly, daily, and hourly). Significantly, drier catchments are shown to
                     be more sensitive to small-scale perturbation than humid catchments. We conclude that the downward analysis approach is a
                     means to better understand the significance of landscape variability upon catchment response. Consequential knowledge can
                     begin to explain data requirements and requisite model complexity and to provide insight into the ability to reliably predict
                     water balance behavior. These are important first steps toward the longer-term objective of reliably predicting water balance
                     variability across ungauged basins.
                  },
    author = {Farmer, Darren and Sivapalan, Murugesu and Jothityangkoon, Chatchai},
    citeulike-article-id = {763793},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2003/2001WR000328.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2001WR000328},
    day = {18},
    doi = {10.1029/2001WR000328},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {models, topdown},
    month = {February},
    number = {2},
    pages = {1035+},
    posted-at = {2009-09-03 06:47:57},
    priority = {2},
    title = {Climate, soil, and vegetation controls upon the variability of water balance in temperate and semiarid landscapes: Downward approach to water balance analysis},
    url = {http://dx.doi.org/10.1029/2001WR000328},
    volume = {39},
    year = {2003}
}

@article{NortonChanat:2005,
    author = {Norton, J. and Chanat, J.},
    citeulike-article-id = {5710992},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.matcom.2005.02.029},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0378475405000601},
    day = {20},
    doi = {10.1016/j.matcom.2005.02.029},
    issn = {03784754},
    journal = {Mathematics and Computers in Simulation},
    keywords = {calibration, ihacres, timeseries},
    month = {June},
    number = {1-2},
    pages = {123--134},
    posted-at = {2009-09-03 01:57:55},
    priority = {0},
    title = {Linear time-varying models to investigate complex distributed dynamics: A rainfall-runoff example},
    url = {http://dx.doi.org/10.1016/j.matcom.2005.02.029},
    volume = {69},
    year = {2005}
}

@article{vanWerkhovenEtAl:2009,
    abstract = {Problem complexity for watershed model calibration is heavily dependent on the number of parameters that can be identified during model calibration. This study investigates the use of global sensitivity analysis as a screening tool to reduce the parametric dimensionality of multi-objective hydrological model calibration problems while maximizing the information extracted from hydrological response data. This study shows that by expanding calibration problem formulations beyond traditional, statistical error metrics to also include metrics that capture indices or signatures of hydrological function, it is possible to reduce the complexity of calibration while maintaining high quality model predictions. The sensitivity-guided calibration is demonstrated using the Sacramento Soil Moisture Accounting (SAC-SMA) conceptual rainfall–runoff model of moderate complexity (i.e., up to 14 freely varying parameters). Using both statistical and hydrological metrics, optimization results demonstrate that parameters controlling at least 20\% of the model output variance (through individual effects and interactions) should be included in the calibration process. This threshold generally yields 30–40\% reductions in the number of SAC-SMA parameters requiring calibration – setting the others to a priori values – while maintaining high quality predictions. Two parameters are recommended to be calibrated in all cases (percent impervious area and lower zone tension water storage), three parameters are needed in drier watersheds (additional impervious area, riparian zone vegetation, and percent of percolation going to tension storage), and the lower zone parameters are crucial unless the watershed is very dry. Overall, this study demonstrates that a coupled, multi-objective sensitivity and calibration analysis better captures differences between watersheds during model calibration and serves to maximize the value of available watershed response time series. These contributions are particularly important given the ongoing development of more complex integrated models, which will require new tools to address the growing discrepancy between the information content of hydrological data and the number of model parameters that have to be estimated.},
    author = {van Werkhoven, Kathryn and Wagener, Thorsten and Reed, Patrick and Tang, Yong},
    citeulike-article-id = {5096319},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.advwatres.2009.03.002},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0309170809000438},
    day = {16},
    doi = {10.1016/j.advwatres.2009.03.002},
    issn = {03091708},
    journal = {Advances in Water Resources},
    keywords = {calibration, sensitivity, topdown},
    month = {August},
    number = {8},
    pages = {1154--1169},
    posted-at = {2009-09-02 01:28:31},
    priority = {4},
    title = {Sensitivity-guided reduction of parametric dimensionality for multi-objective calibration of watershed models},
    url = {http://dx.doi.org/10.1016/j.advwatres.2009.03.002},
    volume = {32},
    year = {2009}
}

@article{SivapalanEtAl:2003,
    abstract = {This paper presents an overview of the lsquodownward approachrsquo to hydrologic prediction and attempts to provide a context for the papers appearing in this special issue. The downward approach is seen as a necessary counterpoint to the mechanistic lsquoreductionistrsquo approach that dominates current hydrological model development. It provides a systematic framework to learning from data, including the testing of hypotheses at every step of analysis. It can also be applied in a hierarchical manner: starting from exploring first-order controls in the modelling of catchment response, the model complexity can then be increased in response to deficiencies in reproducing observations at different levels. The remaining contributions of this special issue present a number of applications of the downward approach, including development of parsimonious water balance models with changing time scales by learning from signatures extracted from observed streamflow data at different time scales, regionalization of model parameters, parameterization of effects of sub-grid variability, and standardized statistical approaches to analyse data and to develop model structures. This review demonstrates that the downward approach is not a rigid methodology, but represents a generic framework. It needs to play an increasing role in the future in the development of hydrological models at the catchment scale. Copyright {\copyright} 2003 John Wiley \& Sons, Ltd.},
    address = {Centre for Water Research, University of Western Australia, Crawley, Australia; Institut f\"{u}r Hydraulik, Gew\"{a}sserkunde and Wasserwirtschaft, Technische Universit\"{a}t Wien, Vienna, Austria; CRC for Catchment Hydrology, CSIRO Land and Water, Canberra, Australia},
    author = {Sivapalan, Murugesu and Bl\"{o}schl, G\"{u}nter and Zhang, Lu and Vertessy, Rob},
    citeulike-article-id = {5704831},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hyp.1425},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/104548001/ABSTRACT},
    doi = {10.1002/hyp.1425},
    issn = {1099-1085},
    journal = {Hydrological Processes},
    keywords = {grand, topdown},
    number = {11},
    pages = {2101--2111},
    posted-at = {2009-09-02 00:47:58},
    priority = {2},
    title = {Downward approach to hydrological prediction},
    url = {http://dx.doi.org/10.1002/hyp.1425},
    volume = {17},
    year = {2003}
}

@article{TangEtAl:2006,
    abstract = {This study provides a comprehensive assessment of state-of-the-art evolutionary multiobjective optimization (EMO) tools' relative effectiveness in calibrating hydrologic models. The relative computational efficiency, accuracy, and ease-of-use of the following EMO algorithms are tested: Epsilon Dominance Nondominated Sorted Genetic Algorithm-II (\&epsilon;-NSGAII), the Multiobjective Shuffled Complex Evolution Metropolis algorithm (MOSCEM-UA), and the Strength Pareto Evolutionary Algorithm 2 (SPEA2). This study uses three test cases to compare the algorithms' performances: (1) a standardized test function suite from the computer science literature, (2) a benchmark hydrologic calibration test case for the Leaf River near Collins, Mississippi, and (3) a computationally intensive integrated surface-subsurface model application in the Shale Hills watershed in Pennsylvania. One challenge and contribution of this work is the development of a methodology for comprehensively comparing EMO algorithms that have different search operators and randomization techniques. Overall, SPEA2 attained competitive to superior results for most of the problems tested in this study. The primary strengths of the SPEA2 algorithm lie in its search reliability and its diversity preservation operator. The biggest challenge in maximizing the performance of SPEA2 lies in specifying an effective archive size without a priori knowledge of the Pareto set. In practice, this would require significant trial-and-error analysis, which is problematic for more complex, computationally intensive calibration applications. \&epsilon;-NSGAII appears to be superior to MOSCEM-UA and competitive with SPEA2 for hydrologic model calibration. \&epsilon;-NSGAII's primary strength lies in its ease-of-use due to its dynamic population sizing and archiving which lead to rapid convergence to very high quality solutions with minimal user input. MOSCEM-UA is best suited for hydrologic model calibration applications that have small parameter sets and small model evaluation times. In general, it would be expected that MOSCEM-UA's performance would be met or exceeded by either SPEA2 or \&epsilon;-NSGAII.},
    author = {Tang, Y. and Reed, P. and Wagener, T.},
    citeulike-article-id = {5695462},
    citeulike-linkout-0 = {http://www.hydrol-earth-syst-sci.net/10/289/2006/},
    day = {8},
    journal = {Hydrology and Earth System Sciences},
    keywords = {calibration},
    month = {May},
    number = {2},
    pages = {289--307},
    posted-at = {2009-09-01 05:44:55},
    priority = {3},
    publisher = {Copernicus Publications},
    title = {{H}ow effective and efficient are multiobjective evolutionary algorithms at hydrologic model calibration?},
    url = {http://www.hydrol-earth-syst-sci.net/10/289/2006/},
    volume = {10},
    year = {2006}
}

@article{McIntyreAlQurashi:2009,
    abstract = {When selecting a rainfall–runoff  model  for application to an arid region, the literature dictates the need to consider the spatial features of rainfall and the variability and non-linearity of losses, and to match  model  complexity to the availability and quality of data. In light of this, the metric-conceptual IHACRES  model  is applied to hourly data from a 734 km 2  catchment in Oman, using a semi-distributed representation of rainfall input. Sensitivity analysis is used to guide reduction of the  model  from a 9-parameter version to simpler versions. The performances of the alternative versions, for predicting flow volumes and peaks at the catchment outlet, are inter-compared. Performances are also compared with those achieved using lumped versions of IHACRES, a physics-based  model  and a 2-parameter regression  model.  For peak flows, a 2-parameter non-linear loss  model  with 2-parameter linear routing, applied in semi-distributed mode, achieves the best overall performance. For flow volumes, the same  model  was preferred although the routing component was not required. The principal reasons for the success of these  models  are thought to be their parsimony, representation of spatial rainfall, and ability to compensate for systematic rainfall and flow observation errors. Extra performance is achieved by using a score-based calibration criterion, which is more robust to extreme errors than the fit-based criteria. Although the best performances are poor, with an average absolute relative error across events of 53\% for flow peaks and 36\% for flow volumes, this is not disappointing compared to other applications of this type. Prediction uncertainty is high due to variability of effective parameter values over events, and uncertainty analysis must explicitly represent this variability in order to explain the observations.},
    author = {McIntyre, N. and Al-Qurashi, A.},
    citeulike-article-id = {5695459},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2008.11.001},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815208001977},
    doi = {10.1016/j.envsoft.2008.11.001},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {ihacres, models},
    month = {June},
    number = {6},
    pages = {726--738},
    posted-at = {2009-09-01 05:40:34},
    priority = {4},
    title = {Performance of ten rainfall–runoff models applied to an arid catchment in Oman},
    url = {http://dx.doi.org/10.1016/j.envsoft.2008.11.001},
    volume = {24},
    year = {2009}
}

@article{TrippNiemann:2008,
    abstract = {The objective of this study is to evaluate the performance of a model that simulates local and spatial average soil moisture in a watershed. The model uses well-known expressions for infiltration, evapotranspiration, and groundwater recharge to describe soil moisture dynamics at the local scale. Then, the spatial mean soil moisture is simulated by integrating the local behavior over a probability density function that characterizes the spatial variability of soil saturation. Ultimately, the model requires input of precipitation and potential evapotranspiration (PET) time series and six parameters to simulate the dynamics of the spatial average soil moisture. The model is applied to the Fort Cobb watershed in Oklahoma using one year of data from September 2005 through August 2006. Model performance is evaluated in three main ways. First, the model's ability to reproduce observed local and spatial average soil moisture through calibration is examined. Second, the identifiability and stability of the parameter values are considered to assess uncertainty in the parameter values and errors in the model's mathematical structure. Third, a new method is developed that uses the sensitivities of soil moisture to precipitation and PET to assess the impacts of parameter uncertainty and structural errors on forecasts for unobserved conditions. At the local scale, the model reproduces the soil moisture with a similar degree of accuracy as a more physically-based model (HYDRUS 1D), and both models exhibit some structural errors. The model can also be calibrated to approximately reproduce the spatial average soil moisture observations. However, the model produces a relatively wide range of plausible sensitivities and this range varies depending on the window of time from which the parameters are calibrated. This result implies that parameter uncertainty and model structural errors contribute substantially to model uncertainty for unobserved conditions.},
    author = {Tripp, D. and Niemann, J.},
    citeulike-article-id = {5695395},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jhydrol.2008.01.028},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169408000620},
    day = {8},
    doi = {10.1016/j.jhydrol.2008.01.028},
    issn = {0022-1694},
    journal = {Journal of Hydrology},
    keywords = {uncertainty},
    month = {February},
    posted-at = {2009-09-01 04:29:06},
    priority = {2},
    title = {Evaluating the Parameter Identifiability and Structural Validity of a Probability-Distributed Model for Soil Moisture},
    url = {http://dx.doi.org/10.1016/j.jhydrol.2008.01.028},
    year = {2008}
}

@article{Moore:2007,
    abstract = {The Probability Distributed Model, or PDM, has evolved as a toolkit of model functions that together constitute a lumped rainfall-runoff model capable of representing a variety of catchment-scale hydrological behaviours. Runoff production is represented as a saturation excess runoff process controlled by the absorption capacity (of the canopy, surface and soil) whose variability within the catchment is characterised by a probability density function of chosen form. Soil drainage to groundwater is controlled by the water content in excess of a tension threshold, optionally inhibited by the water content of the receiving groundwater store. Alternatively, a proportional split of runoff to fast (surface storage) and slow (groundwater) pathways can be invoked with no explicit soil drainage function. Recursive solutions to the Horton-Izzard equation are provided for routing flows through these pathways, conveniently considered to yield the surface runoff and baseflow components of the total flow. An alternative routing function employs a transfer function that is discretely-coincident to a cascade of two linear reservoirs in series. For real-time flow forecasting applications, the PDM is complemented by updating methods based on error prediction and state-correction approaches. The PDM has been widely applied throughout the world, both for operational and design purposes. This experience has allowed the PDM to evolve to its current form as a practical toolkit for rainfall-runoff modelling and forecasting.},
    author = {Moore, R. J.},
    citeulike-article-id = {5695392},
    citeulike-linkout-0 = {http://www.hydrol-earth-syst-sci.net/11/483/2007/},
    day = {17},
    journal = {Hydrology and Earth System Sciences},
    keywords = {models, software},
    month = {January},
    number = {1},
    pages = {483--499},
    posted-at = {2009-09-01 04:23:41},
    priority = {5},
    publisher = {Copernicus Publications},
    title = {The PDM rainfall-runoff model},
    url = {http://www.hydrol-earth-syst-sci.net/11/483/2007/},
    volume = {11},
    year = {2007}
}

@article{IvkovicEtAl:2009,
    abstract = {Allocations of river and groundwater have been traditionally managed separately in Australia and many other parts of the world even though in many regions groundwater and river systems are hydraulically connected. Groundwater extractions in areas where river systems are hydraulically connected can cause substantial impacts to river flows particularly base flows or low flows, which are considered to be ecologically important. Traditional groundwater modelling approaches tend to be undertaken on time-scales of weeks or months and are not sufficient to demonstrate the impacts of groundwater extractions in many river systems, particularly where flows are ephemeral. The impacts of groundwater extraction on surface water flows is considered using a simple, conceptual, lumped-parameter modelling approach called IHACRES\_GW. The Coxs Creek catchment in the Namoi River Basin, New South Wales is used as a case study. Groundwater extractions are having significant impacts on base flows in this area and current policies will not be effective in reducing these impacts. These findings demonstrate the potential of such a modelling approach, when used in conjunction with traditional groundwater models, in setting allocation limits to assess impacts on river flows.},
    author = {Ivkovic, K. M. and Letcher, R. A. and Croke, B. F. W.},
    citeulike-article-id = {3952539},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/08120090802541945},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/tandf/aes/2009/00000056/00000001/art00009},
    doi = {10.1080/08120090802541945},
    issn = {0812-0099},
    journal = {Australian Journal of Earth Sciences},
    keywords = {groundwater, ihacres, models},
    month = {February},
    number = {1},
    pages = {71--80},
    posted-at = {2009-09-01 01:53:35},
    priority = {2},
    publisher = {Taylor and Francis Ltd},
    title = {Use of a simple surface-groundwater interaction model to inform water management},
    url = {http://dx.doi.org/10.1080/08120090802541945},
    volume = {56},
    year = {2009}
}

@article{HerronCroke:2009,
    abstract = {The growing realisation that groundwater and surface water systems are components of connected hydrologic system has in recent years sparked the development of integrated surface–ground water models. In this paper, a version of the IHACRES rainfall-runoff model is presented, in which the CMD module for calculating effective rainfall is coupled to a streamflow-groundwater module, and applied to the Coxs Creek catchment, a variably gaining-losing stream system in Australia. The aim is to determine the capacity for the coupled model to capture the switching off–on behaviour evident in the observed flow record. Model performance can be improved in terms of event prediction, volume of baseflow and the percentile of flow cessation, through manipulation of CMD parameters, however, improvements in some performance criteria come at the expense of performance in others. An analysis of the input rainfall time-series, generated using a standard weighted Thiessen polygon approach, reveals mismatches between observed streamflow events and the occurrence of rainfall, which impose major limits on model performance. The challenge is to develop a simple lumped rainfall-runoff model that has the potential to improve system understanding and allow for meaningful exploration of alternate climate, groundwater extraction and land use change scenarios, given a situation of data poor catchments in many parts of Australia.},
    author = {Herron, Natasha and Croke, Barry},
    citeulike-article-id = {5695262},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.matcom.2008.08.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0378475408002929},
    doi = {10.1016/j.matcom.2008.08.007},
    issn = {03784754},
    journal = {Mathematics and Computers in Simulation},
    keywords = {groundwater, ihacres, models},
    month = {May},
    number = {9},
    pages = {2689--2700},
    posted-at = {2009-09-01 01:48:34},
    priority = {3},
    title = {Including the influence of groundwater exchanges in a lumped rainfall-runoff model},
    url = {http://dx.doi.org/10.1016/j.matcom.2008.08.007},
    volume = {79},
    year = {2009}
}

@article{Beven:2008,
    abstract = {No Abstract.},
    address = {Lancaster Environment Centre, Lancaster University, Lancaster, UK; Geocentrum, Uppsala University, Uppsala, Sweden},
    author = {Beven, Keith},
    citeulike-article-id = {3072889},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hyp.7108},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/120747792/ABSTRACT},
    doi = {10.1002/hyp.7108},
    issn = {1099-1085},
    journal = {Hydrological Processes},
    keywords = {grand, uncertainty},
    number = {17},
    pages = {3549--3553},
    posted-at = {2009-09-01 00:42:21},
    priority = {4},
    title = {On doing better hydrological science},
    url = {http://dx.doi.org/10.1002/hyp.7108},
    volume = {22},
    year = {2008}
}

@article{YoungRatto:2008,
    abstract = {Abstract  The paper considers the differences between hypothetico-deductive and inductive modeling: between modelers who put their primary trust in their scientific intuition about the nature of an environmental model and tend to produce quite complex computer simulation models; and those who prefer to rely on the analysis of observational data to identify the simplest form of model that can represent these data. The tension that sometimes arises because of the different philosophical outlooks of these two modeling groups can be harmful because it tends to fractionate the effort that goes into the investigation of important environmental problems, such as global warming. In an attempt to improve this situation, the paper will outline a new Data-Based Mechanistic (DBM) approach to modeling that tries to meld together the best aspects of these two modeling philosophies in order to develop a unified approach that combines the hypothetico-deductive virtues of good scientific intuition and simulation modeling with the pragmatism of inductive data-based modeling, where more objective inference from data is the primary driving force. In particular, it demonstrates the feasibility of a new method for complex simulation model emulation, in which the methodological tools of DBM modeling are used to develop a reduced dynamic order model that represents the 'dominant modes' of the complex simulation model. In this form, the 'dynamic emulation' model can be compared with the DBM model obtained directly from the analysis of real data and any tensions between the two modeling approaches may be relaxed to produce models that suit multiple modeling objectives.},
    author = {Young, P. C. and Ratto, Marco},
    citeulike-article-id = {3632854},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00477-008-0271-1},
    citeulike-linkout-1 = {http://www.springerlink.com/content/e0606854033344m3},
    day = {15},
    doi = {10.1007/s00477-008-0271-1},
    issn = {1436-3259},
    journal = {Stochastic Environmental Research and Risk Assessment},
    keywords = {grand, systems, topdown},
    month = {October},
    posted-at = {2009-08-31 06:18:14},
    priority = {4},
    title = {A unified approach to environmental systems modeling},
    url = {http://dx.doi.org/10.1007/s00477-008-0271-1},
    year = {2008}
}

@article{VrugtEtAl:2009:glue,
    abstract = {Abstract  In recent years, a strong debate has emerged in the hydrologic literature regarding what constitutes an appropriate framework for uncertainty estimation. Particularly, there is strong disagreement whether an uncertainty framework should have its roots within a proper statistical (Bayesian) context, or whether such a framework should be based on a different philosophy and implement informal measures and weaker inference to summarize parameter and predictive distributions. In this paper, we compare a formal Bayesian approach using Markov Chain Monte Carlo (MCMC) with generalized likelihood uncertainty estimation (GLUE) for assessing uncertainty in conceptual watershed modeling. Our formal Bayesian approach is implemented using the recently developed differential evolution adaptive metropolis (DREAM) MCMC scheme with a likelihood function that explicitly considers model structural, input and parameter uncertainty. Our results demonstrate that DREAM and GLUE can generate very similar estimates of total streamflow uncertainty. This suggests that formal and informal Bayesian approaches have more common ground than the hydrologic literature and ongoing debate might suggest. The main advantage of formal approaches is, however, that they attempt to disentangle the effect of forcing, parameter and model structural error on total predictive uncertainty. This is key to improving hydrologic theory and to better understand and predict the flow of water through catchments.},
    author = {Vrugt, Jasper A. and Braak, Cajo J. F. and Gupta, Hoshin V. and Robinson, Bruce A.},
    citeulike-article-id = {3632841},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00477-008-0274-y},
    citeulike-linkout-1 = {http://www.springerlink.com/content/8ur56u6644063813},
    doi = {10.1007/s00477-008-0274-y},
    issn = {1436-3259},
    journal = {Stochastic Environmental Research and Risk Assessment},
    keywords = {calibration, sensitivity, statistics},
    number = {7},
    pages = {1011--1026},
    posted-at = {2009-08-31 06:04:32},
    priority = {5},
    title = {Equifinality of formal (DREAM) and informal (GLUE) Bayesian approaches in hydrologic modeling?},
    url = {http://dx.doi.org/10.1007/s00477-008-0274-y},
    volume = {23},
    year = {2009}
}

@article{TaylorEtAl:2007,
    abstract = {The  Data-Based Mechanistic  (DBM) modelling philosophy emphasises the importance of parametrically efficient, low order, 'dominant mode' models, as well as the development of stochastic methods and the associated statistical analysis required for their identification and estimation. Furthermore, it stresses the importance of explicitly acknowledging the basic uncertainty in the process, which is particularly important for the characterisation and forecasting of environmental and other poorly defined systems. The paper focuses on a Matlab ®  compatible toolbox that has evolved from this DBM modelling research. Based around a state space and transfer function estimation framework,  Captain  extends Matlab ®  to allow, in the most general case, for the identification and estimation of a wide range of unobserved components models. Uniquely, however,  Captain  focuses on models with both time variable and state dependent parameters and has recently been implemented with the latest methodological developments in this regard. Here, the main innovations are: the automatic optimisation of the hyper-parameters, which define the statistical properties of the time variable parameters; the provision of smoothed as well as filtered parameter estimates; the robust and statistically efficient identification and estimation of both discrete and continuous time transfer function models; and the availability of various special model structures that have wide application potential in the environmental sciences.},
    author = {Taylor, C. and Pedregal, D. and Young, P. and Tych, W.},
    citeulike-article-id = {5687087},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2006.03.002},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815206000636},
    doi = {10.1016/j.envsoft.2006.03.002},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {software, statistics, timeseries},
    month = {June},
    number = {6},
    pages = {797--814},
    posted-at = {2009-08-31 05:31:31},
    priority = {0},
    title = {Environmental time series analysis and forecasting with the Captain toolbox},
    url = {http://dx.doi.org/10.1016/j.envsoft.2006.03.002},
    volume = {22},
    year = {2007}
}

@article{Beven:2006,
    abstract = {This essay discusses some of the issues involved in the identification and predictions of hydrological models given some calibration data. The reasons for the incompleteness of traditional calibration methods are discussed. The argument is made that the potential for multiple acceptable models as representations of hydrological and other environmental systems (the equifinality thesis) should be given more serious consideration than hitherto. It proposes some techniques for an extended GLUE methodology to make it more rigorous and outlines some of the research issues still to be resolved.},
    author = {Beven, Keith},
    citeulike-article-id = {4057953},
    citeulike-linkout-0 = {http://www.sciencedirect.com/science/article/B6V6C-4H16S4M-1/2/571c8821621c803522cc823147bef169},
    day = {30},
    journal = {Journal of Hydrology},
    keywords = {calibration, grand, sensitivity},
    month = {March},
    number = {1-2},
    pages = {18--36},
    posted-at = {2009-08-31 03:52:22},
    priority = {3},
    title = {A manifesto for the equifinality thesis},
    url = {http://www.sciencedirect.com/science/article/B6V6C-4H16S4M-1/2/571c8821621c803522cc823147bef169},
    volume = {320},
    year = {2006}
}

@article{FeniciaEtAl:2008:Auxdata,
    abstract = {A priori determined model structures are common in catchment rainfall-runoff modeling. While this has resulted in many ready-to-use
                     modeling tools, there are several shortcomings of a one-size-fits-all model structure. The uniqueness of catchments with respect
                     to their hydrological behavior and the need to adapt model complexity to data availability challenge this status quo. We present
                     a flexible approach to model development where the model structure is adapted progressively based on catchment characteristics
                     and the data described by the experimentalist. We demonstrate this approach with the Maimai catchment in New Zealand, a location
                     with a large availability of data, including stream discharge, groundwater levels, and stream isotope measurements. Different
                     types of data are introduced progressively, and the architecture of the model is adjusted in a stepwise fashion to better
                     describe the processes suggested by the new data sources. The revised models are developed in a way to strike a balance between
                     model complexity and data availability, by keeping models as simple as possible, but complex enough to explain the dynamics
                     of the data. Our work suggests that (1) discharge data provides information on the dynamics of storage (represented by the
                      ” free” water in the reservoirs) subject to pressure wave propagation generated by rainfall into the catchment, (2) groundwater
                     data provides information on thresholds and on the contribution of different portions of the catchment to stream discharge,
                     and (3) isotope data provides information on particle transport and mixing of the rainfall with the storage present in the
                     catchment. Moreover, while groundwater data appear to be correlated with discharge data, and only a marginal improvement could
                     be obtained adding this information to the model development process, isotope data appear to provide an orthogonal view on
                     catchment behavior. This result contributes to understanding the value of data for modeling, which may serve as a guidance
                     in the process of gauging ungauged catchments.
                  },
    author = {Fenicia, Fabrizio and Mcdonnell, Jeffrey J. and Savenije, Hubert H. G.},
    citeulike-article-id = {5686994},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2008/2007WR006386.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2007WR006386},
    day = {25},
    doi = {10.1029/2007WR006386},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {grand, models, topdown},
    month = {June},
    number = {6},
    pages = {W06419+},
    posted-at = {2009-08-31 02:43:22},
    priority = {5},
    title = {Learning from model improvement: On the contribution of complementary data to process understanding},
    url = {http://dx.doi.org/10.1029/2007WR006386},
    volume = {44},
    year = {2008}
}

@article{ChoiBeven:2007,
    author = {Choi, H. and Beven, K.},
    citeulike-article-id = {4504977},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jhydrol.2006.07.012},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169406003647},
    day = {15},
    doi = {10.1016/j.jhydrol.2006.07.012},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {calibration, sensitivity},
    month = {January},
    number = {3-4},
    pages = {316--336},
    posted-at = {2009-08-31 02:25:26},
    priority = {3},
    title = {Multi-period and multi-criteria model conditioning to reduce prediction uncertainty in an application of TOPMODEL within the GLUE framework},
    url = {http://dx.doi.org/10.1016/j.jhydrol.2006.07.012},
    volume = {332},
    year = {2007}
}

@article{Croke:2006,
    abstract = {A technique is presented for empirical and parametric estimation of an average event unit hydrograph response curve solely from measured streamflow data for use in rainfall-runoff models with a focus on modelling flow for natural resource management. As the technique does not require rainfall data, the unit hydrograph can be derived solely from streamflow data at a temporal resolution appropriate for the response of the catchment. The response curves derived for a number of stations show a power law relationship of decay in flow after peak that can be described using a three-parameter function. The approach is best suited to ephemeral streamflow regimes dominated by surface and near-surface runoff (quick-flow component) where flow events are well-separated and largely independent of each other. Analysis of the derived unit hydrograph for 28 quick-flow-dominated catchments illustrates the range of parameter values obtained in fitting the power law.},
    author = {Croke, B. F. W.},
    citeulike-article-id = {5686990},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.advwatres.2005.06.005},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0309170805001673},
    doi = {10.1016/j.advwatres.2005.06.005},
    issn = {03091708},
    journal = {Advances in Water Resources},
    keywords = {ihacres, statistics},
    month = {April},
    number = {4},
    pages = {493--502},
    posted-at = {2009-08-31 02:21:36},
    priority = {3},
    title = {A technique for deriving an average event unit hydrograph from streamflow-only data for ephemeral quick-flow-dominant catchments},
    url = {http://dx.doi.org/10.1016/j.advwatres.2005.06.005},
    volume = {29},
    year = {2006}
}

@article{CrokeEtAl:2006:Java,
    author = {Croke, B. and Andrews, F. and Jakeman, A. and Cuddy, S. and Luddy, A.},
    citeulike-article-id = {5686989},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2005.07.003},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815205001490},
    doi = {10.1016/j.envsoft.2005.07.003},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {ihacres, software},
    month = {March},
    number = {3},
    pages = {426--427},
    posted-at = {2009-08-31 02:19:33},
    priority = {0},
    title = {IHACRES Classic Plus: A redesign of the IHACRES rainfall-runoff model},
    url = {http://dx.doi.org/10.1016/j.envsoft.2005.07.003},
    volume = {21},
    year = {2006}
}

@article{BaiEtAl:2009,
    abstract = {This study introduces a top-down strategy for model evaluation and selection under uncertainty in which watershed model structures with increasing complexity are applied to twelve watersheds across a hydro-climatic gradient within the United States (US). The models' complexities and their related assumptions provide an indication of the dominant controls on the watershed response at the inter-annual, intra-annual, monthly, and daily time scales as captured in the water balance signatures (or metrics) used in this study. The ability of the models to capture the water balance signatures is evaluated in an ensemble framework with respect to their reliability (Is the model ensemble capturing the observed signature?) and with their shape (Is the model structure capable of representing an observed signature's variability?). Model selection is automated by combining the reliability and shape performance measures in a fuzzy rule system. Our results suggest that the framework can be tuned to function as a screening tool that formalizes our model selection process. This fuzzy model selection framework enhances our ability to automatically select parsimonious model structures for large databases of watersheds and therefore provides an important step towards understanding how controls on the watershed response vary with landscape and climatic characteristics. This understanding further advances our ability for model-based watershed classification.},
    author = {Bai, Yaoling and Wagener, Thorsten and Reed, Patrick},
    citeulike-article-id = {4778993},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2008.12.012},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815208002399},
    doi = {10.1016/j.envsoft.2008.12.012},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {grand, topdown},
    month = {August},
    number = {8},
    pages = {901--916},
    posted-at = {2009-08-31 02:16:28},
    priority = {5},
    title = {A top-down framework for watershed model evaluation and selection under uncertainty},
    url = {http://dx.doi.org/10.1016/j.envsoft.2008.12.012},
    volume = {24},
    year = {2009}
}

@article{JakemanEtAl:2006,
    abstract = {Models are increasingly being relied upon to inform and support natural resource management. They are incorporating an ever broader range of disciplines and now often confront people without strong quantitative or model-building backgrounds. These trends imply a need for wider awareness of what constitutes good model-development practice, including reporting of models to users and sceptical review of models by users. To this end the paper outlines ten basic steps of good, disciplined model practice. The aim is to develop purposeful, credible models from data and prior knowledge, in consort with end-users, with every stage open to critical review and revision. Best practice entails identifying clearly the clients and objectives of the modelling exercise; documenting the nature (quantity, quality, limitations) of the data used to construct and test the model; providing a strong rationale for the choice of model family and features (encompassing review of alternative approaches); justifying the techniques used to calibrate the model; serious analysis, testing and discussion of model performance; and making a resultant statement of model assumptions, utility, accuracy, limitations, and scope for improvement. In natural resource management applications, these steps will be a learning process, even a partnership, between model developers, clients and other interested parties.},
    author = {Jakeman, A. and Letcher, R. and Norton, J.},
    citeulike-article-id = {1586959},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2006.01.004},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815206000107},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6VHC-4JHMFSH-1/2/7ee0a43b037d163ed8287c6c143638e0},
    doi = {10.1016/j.envsoft.2006.01.004},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {grand, topdown},
    month = {May},
    number = {5},
    pages = {602--614},
    posted-at = {2009-08-31 01:59:03},
    priority = {2},
    title = {Ten iterative steps in development and evaluation of environmental models},
    url = {http://dx.doi.org/10.1016/j.envsoft.2006.01.004},
    volume = {21},
    year = {2006}
}

@article{WagenerMcIntyre:2007,
    abstract = {Being able to work with mathematical models of hydrological and environmental systems becomes increasingly important for students of civil and environmental engineering departments. Courses or course sections teaching the specific skills needed are slowly making their way into the curriculum. This paper discusses the requirements for tools to teach these topics. Two example tools for model identification and for model evaluation are presented in detail. The paper closes with a section on our experience of using these tools in undergraduate and graduate civil and environmental engineering education in the UK and in the USA.},
    author = {Wagener, T. and McIntyre, N.},
    citeulike-article-id = {5686975},
    journal = {Computers in Education Journal},
    keywords = {software},
    number = {3},
    pages = {16--26},
    posted-at = {2009-08-31 01:55:55},
    priority = {3},
    title = {Tools for teaching hydrological and environmental modeling},
    volume = {17},
    year = {2007}
}

@article{DuanEtAl:1994,
    abstract = {The difficulties involved in calibrating conceptual watershed models have, in the past, been partly attributable to the lack of robust optimization tools. Recently, a global optimization method known as the SCE-UA (shuffled complex evolution method developed at The University of Arizona) has shown promise as an effective and efficient optimization technique for calibrating watershed models. Experience with the method has indicated that the effectiveness and efficiency of the algorithm are influenced by the choice of the algorithmic parameters. This paper first reviews the essential concepts of the SCE-UA method and then presents the results of several experimental studies in which the National Weather Service river forecast system-soil moisture accounting (NWSRFS-SMA) model, used by the National Weather Service for river and flood forecasting, was calibrated using different algorithmic parameter setups. On the basis of these results, the recommended values for the algorithmic parameters are given. These values should also help to provide guidelines for other users of the SCE-UA method.},
    author = {Duan, Q. and Sorooshian, S. and Gupta, V.},
    citeulike-article-id = {5686972},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0022-1694(94)90057-4},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0022169494900574},
    day = {15},
    doi = {10.1016/0022-1694(94)90057-4},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {calibration},
    month = {June},
    number = {3-4},
    pages = {265--284},
    posted-at = {2009-08-31 01:49:12},
    priority = {0},
    title = {Optimal use of the SCE-UA global optimization method for calibrating watershed models},
    url = {http://dx.doi.org/10.1016/0022-1694(94)90057-4},
    volume = {158},
    year = {1994}
}

@article{DuanEtAl:1992,
    abstract = {The successful application of a conceptual rainfall-runoff (CRR) model depends on how well it is calibrated. Despite the popularity                     of CRR models, reports in the literature indicate that it is typically difficult, if not impossible, to obtain unique optimal                     values for their parameters using automatic calibration methods. Unless the best set of parameters associated with a given                     calibration data set can be found, it is difficult to determine how sensitive the parameter estimates (and hence the model                     forecasts) are to factors such as input and output data error, model error, quantity and quality of data, objective function                     used, and so on. Results are presented that establish clearly the nature of the multiple optima problem for the research CRR                     model SIXPAR. These results suggest that the CRR model optimization problem is more difficult than had been previously thought                     and that currently used local search procedures have a very low probability of successfully finding the optimal parameter                     sets. Next, the performance of three existing global search procedures are evaluated on the model SIXPAR. Finally, a powerful                     new global optimization procedure is presented, entitled the shuffled complex evolution (SCE-UA) method, which was able to                     consistently locate the global optimum of the SIXPAR model, and appears to be capable of efficiently and effectively solving                     the CRR model optimization problem.},
    author = {Duan, Qingyun and Sorooshian, Soroosh and Gupta, Vijai},
    citeulike-article-id = {708619},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/1992/91WR02985.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/91WR02985},
    doi = {10.1029/91WR02985},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {calibration},
    number = {4},
    pages = {1015--1031},
    posted-at = {2009-08-31 01:47:08},
    priority = {2},
    title = {Effective and Efficient Global Optimization for Conceptual Rainfall-Runoff Models},
    url = {http://dx.doi.org/10.1029/91WR02985},
    volume = {28},
    year = {1992}
}

@article{VrugtEtAl:2006,
    abstract = {Hydrological models generally contain parameters that cannot be measured directly, but can only be meaningfully inferred by calibration against a historical record of input–output data. While considerable progress has been made in the development and application of automatic procedures for model calibration, such methods have received criticism for their lack of rigor in treating uncertainty in the parameter estimates. In this paper, we apply the recently developed Shuffled Complex Evolution Metropolis algorithm (SCEM-UA) to stochastic calibration of the parameters in the Sacramento Soil Moisture Accounting model (SAC-SMA) model using historical data from the Leaf River in Mississippi. The SCEM-UA algorithm is a Markov Chain Monte Carlo sampler that provides an estimate of the most likely parameter set and underlying posterior distribution within a single optimization run. In particular, we explore the relationship between the length and variability of the streamflow data and the Bayesian uncertainty associated with the SAC-SMA model parameters and compare SCEM-UA derived parameter values with those obtained using deterministic SCE-UA calibrations. Most significantly, for the Leaf River catchments under study our results demonstrate that most of the 13 SAC-SMA parameters are well identified by calibration to daily streamflow data suggesting that this data contains more information than has previously been reported in the literature.},
    author = {Vrugt, J. and Gupta, H. and Dekker, S. and Sorooshian, S. and Wagener, T. and Bouten, W.},
    citeulike-article-id = {5686966},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jhydrol.2005.10.041},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022169405005482},
    day = {30},
    doi = {10.1016/j.jhydrol.2005.10.041},
    issn = {00221694},
    journal = {Journal of Hydrology},
    keywords = {calibration, topdown},
    month = {June},
    number = {1-4},
    pages = {288--307},
    posted-at = {2009-08-31 01:22:37},
    priority = {4},
    title = {Application of stochastic parameter optimization to the Sacramento Soil Moisture Accounting model},
    url = {http://dx.doi.org/10.1016/j.jhydrol.2005.10.041},
    volume = {325},
    year = {2006}
}

@article{WagenerEtAl:2001,
    abstract = {Many existing hydrological modelling procedures do not make best use of available information, resulting in non-minimal uncertainties in model structure and parameters, and a lack of detailed information regarding model behaviour. A framework is required that balances the level of model complexity supported by the available data with the level of performance suitable for the desired application. Tools are needed that make optimal use of the information available in the data to identify model structure and parameters, and that allow a detailed analysis of model behaviour. This should result in appropriate levels of model complexity as a function of available data, hydrological system characteristics and modelling purpose. This paper introduces an analytical framework to achieve this, and tools to use within it, based on a multi-objective approach to model calibration and analysis. The utility of the framework is demonstrated with an example from the field of rainfall-runoff modelling.</p> <p  style="line-height: 20px;"><b>Keywords: </b>hydrological modelling, multi-objective calibration, model complexity,           parameter identifiability},
    author = {Wagener, T. and Boyle, D. P. and Lees, M. J. and Wheater, H. S. and Gupta, H. V. and Sorooshian, S.},
    citeulike-article-id = {5686332},
    citeulike-linkout-0 = {http://www.hydrol-earth-syst-sci.net/5/13/1999/},
    day = {30},
    journal = {Hydrology and Earth System Sciences},
    keywords = {ihacres, software, topdown},
    month = {November},
    number = {1},
    pages = {13--26},
    posted-at = {2009-08-31 01:11:37},
    priority = {4},
    publisher = {Copernicus Publications},
    title = {{A} framework for development and application of hydrological models},
    url = {http://www.hydrol-earth-syst-sci.net/5/13/1999/},
    volume = {5},
    year = {2001}
}

@article{ZeileisEtAl:2002,
    author = {Zeileis, Achim and Leisch, Friedrich and Hornik, Kurt and Kleiber, Christian},
    citeulike-article-id = {5686325},
    citeulike-linkout-0 = {http://www.jstatsoft.org/v07/i02/},
    journal = {Journal of Statistical Software},
    keywords = {r, software, statistics},
    number = {2},
    pages = {1--38},
    posted-at = {2009-08-31 00:54:21},
    priority = {2},
    title = {strucchange: An R Package for Testing for Structural Change in Linear Regression Models},
    url = {http://www.jstatsoft.org/v07/i02/},
    volume = {7},
    year = {2002}
}

@article{ZeileisGrothendieck:2005,
    author = {Zeileis, Achim and Grothendieck, Gabor},
    citeulike-article-id = {5686324},
    citeulike-linkout-0 = {http://www.jstatsoft.org/v14/i06/},
    journal = {Journal of Statistical Software},
    keywords = {r, software, timeseries},
    number = {6},
    pages = {1--27},
    posted-at = {2009-08-31 00:54:21},
    priority = {0},
    title = {zoo: S3 Infrastructure for Regular and Irregular Time Series},
    url = {http://www.jstatsoft.org/v14/i06/},
    volume = {14},
    year = {2005}
}

@article{Wood:2004,
    author = {Wood, S. N.},
    citeulike-article-id = {5686322},
    journal = {Journal of the American Statistical Association},
    keywords = {statistics},
    number = {467},
    pages = {673--686},
    posted-at = {2009-08-31 00:54:01},
    priority = {2},
    title = {Stable and efficient multiple smoothing parameter estimation for generalized additive models},
    volume = {99},
    year = {2004}
}

@article{YeEtAl:1997,
    author = {Ye, W. and Bates, B. C. and Viney, N. R. and Sivapalan, M. and Jakeman, A. J.},
    citeulike-article-id = {5686321},
    journal = {Water Resources Research},
    keywords = {ihacres, models},
    pages = {153--166},
    posted-at = {2009-08-31 00:53:40},
    priority = {2},
    title = {Performance of conceptual rainfall-runoff models in low-yielding ephemeral catchments},
    volume = {33},
    year = {1997}
}

@article{WhiteheadEtAl:1979,
    author = {Whitehead, P. G. and Young, P. C. and Hornberger, G. M.},
    citeulike-article-id = {5686320},
    journal = {Water Resources Research},
    keywords = {ihacres, models},
    pages = {1155--1169},
    posted-at = {2009-08-31 00:53:40},
    priority = {2},
    title = {A systems model of streamflow and water quality in the Bedford-Ouse: 1. Streamflow modelling},
    volume = {13},
    year = {1979}
}

@manual{RCore,
    address = {Vienna, Austria},
    author = {{R Development Core Team}},
    citeulike-article-id = {5686319},
    citeulike-linkout-0 = {http://www.R-project.org/},
    isbn = {3-900051-07-0},
    keywords = {r},
    organization = {R Foundation for Statistical Computing},
    posted-at = {2009-08-31 00:52:48},
    priority = {1},
    title = {R: A Language and Environment for Statistical Computing},
    url = {http://www.R-project.org/},
    year = {2010}
}

@book{PetrisEtAl:2009,
    author = {Petris, Giovanni and Petrone, Sonia and Campagnoli, Patriza},
    citeulike-article-id = {5686318},
    isbn = {978-0-387-77237-0},
    keywords = {r},
    posted-at = {2009-08-31 00:52:48},
    priority = {2},
    publisher = {Springer},
    series = {Use R!},
    title = {Dynamic Linear Models with {R}},
    year = {2009}
}

@article{MebaneSekhon:2009,
    author = {Walter and Sekhon, Jasjeet S.},
    citeulike-article-id = {5686317},
    citeulike-linkout-0 = {http://www.jstatsoft.org/},
    comment = {Forthcoming},
    journal = {Journal of Statistical Software},
    keywords = {r},
    posted-at = {2009-08-31 00:52:48},
    priority = {2},
    title = {Genetic Optimization Using Derivatives: The {rgenoud} Package for {R}},
    url = {http://www.jstatsoft.org/},
    year = {2009}
}

@book{Ljung:1999,
    author = {Ljung, Lennart},
    citeulike-article-id = {5686316},
    edition = {2nd},
    keywords = {statistics},
    posted-at = {2009-08-31 00:52:17},
    priority = {2},
    publisher = {Prentice Hall},
    title = {System Identification: Theory for the User},
    year = {1999}
}

@article{Littlewood:2008,
    author = {Littlewood, I. G.},
    citeulike-article-id = {5686314},
    journal = {Hydrological Sciences Journal},
    keywords = {ihacres, models},
    number = {4},
    pages = {685--695},
    posted-at = {2009-08-31 00:51:08},
    priority = {2},
    title = {Data time-step dependency of conceptual rainfall-streamflow model parameters: an empirical study with implications for regionalisation},
    volume = {53},
    year = {2008}
}

@article{KokkonenJakeman:2001,
    author = {Kokkonen, T. S. and Jakeman, A. J.},
    citeulike-article-id = {5686313},
    journal = {Water Resources Research},
    keywords = {ihacres, topdown},
    number = {9},
    pages = {2345--2352},
    posted-at = {2009-08-31 00:51:08},
    priority = {0},
    title = {A comparison of metric and conceptual approaches in rainfall-runoff modelling and its implications},
    volume = {37},
    year = {2001}
}

@article{JakemanHornberger:1993,
    author = {Jakeman, A. J. and Hornberger, G. M.},
    citeulike-article-id = {5686312},
    journal = {Water Resources Research},
    keywords = {grand, ihacres, models, topdown},
    pages = {2637--2649},
    posted-at = {2009-08-31 00:51:08},
    priority = {0},
    title = {How much complexity is warranted in a rainfall-runoff model?},
    volume = {29},
    year = {1993}
}

@article{JakemanEtAl:1991,
    author = {Jakeman, A. J. and Thomas, G. A. and Dietrich, C. R.},
    citeulike-article-id = {5686311},
    journal = {Journal of Forecasting},
    keywords = {ihacres, models},
    pages = {319--346},
    posted-at = {2009-08-31 00:51:08},
    priority = {2},
    title = {System Identification and Validation for Output Prediction of a Dynamic Hydrologic Process},
    volume = {10},
    year = {1991}
}

@article{JakemanEtAl:1990,
    author = {Jakeman, A. J. and Littlewood, I. G. and Whitehead, P. G.},
    citeulike-article-id = {5686310},
    journal = {Journal of Hydrology},
    keywords = {ihacres, models},
    pages = {275--300},
    posted-at = {2009-08-31 00:51:08},
    priority = {0},
    title = {Computation of the instantaneous unit hydrograph and identifiable component flows with application to two small upland catchments},
    volume = {117},
    year = {1990}
}

@article{IhakaGentleman:1996,
    author = {Ihaka, R. and Gentleman, R.},
    citeulike-article-id = {5686309},
    journal = {Journal of Computational and Graphical Statistics},
    keywords = {r},
    pages = {299--314},
    posted-at = {2009-08-31 00:48:01},
    priority = {2},
    title = {R: A language for data analysis and graphics},
    volume = {5},
    year = {1996}
}

@article{GentlemanTempleLang:2007,
    author = {Gentleman, R. and Temple Lang, D.},
    citeulike-article-id = {5686308},
    comment = {doi:10.1198/106186007X178663},
    journal = {Journal of Computational and Graphical Statistics},
    keywords = {r},
    number = {1},
    pages = {1--23},
    posted-at = {2009-08-31 00:48:01},
    priority = {2},
    title = {Statistical Analyses and Reproducible Research},
    volume = {16},
    year = {2007}
}

@article{Fox:2008,
    author = {Fox, J.},
    citeulike-article-id = {5686307},
    comment = {Shows evidence of exponential growth in number of R packages 2001-2008.},
    journal = {R News},
    keywords = {r},
    pages = {1--2},
    posted-at = {2009-08-31 00:48:01},
    priority = {0},
    title = {Editorial},
    volume = {8/2},
    year = {2008}
}

@book{Faraway:2006,
    address = {Boca Raton, FL},
    author = {Faraway, Julian J.},
    citeulike-article-id = {5686306},
    isbn = {1-584-88424-X},
    keywords = {r},
    posted-at = {2009-08-31 00:48:01},
    priority = {2},
    publisher = {Chapman \& Hall/CRC},
    title = {Extending Linear Models with {R}: Generalized Linear, Mixed Effects and Nonparametric Regression Models},
    year = {2006}
}

@article{EvansJakeman:1998,
    author = {Evans, J. P. and Jakeman, A. J.},
    citeulike-article-id = {5686304},
    journal = {Environmental Modelling and Software},
    keywords = {ihacres, models},
    pages = {385--393},
    posted-at = {2009-08-31 00:47:22},
    priority = {2},
    title = {Development of a simple, catchment-scale, rainfall- evapotranspiration- runoff model},
    volume = {13},
    year = {1998}
}

@article{CrokeJakeman:2004,
    author = {Croke, B. F. W. and Jakeman, A. J.},
    citeulike-article-id = {5686303},
    journal = {Environmental Modelling and Software},
    keywords = {ihacres, models},
    pages = {1--5},
    posted-at = {2009-08-31 00:47:22},
    priority = {2},
    title = {A Catchment Moisture Deficit module for the IHACRES rainfall-runoff model},
    volume = {19},
    year = {2004}
}

@article{Bates:2008,
    author = {Bates, D.},
    citeulike-article-id = {5686301},
    journal = {Technometrics},
    keywords = {opensource, r},
    number = {4},
    pages = {439--440},
    posted-at = {2009-08-31 00:45:18},
    priority = {0},
    title = {Comment on Leland Wilkinson, ``The Future of Statistical Computing''},
    volume = {50},
    year = {2008}
}

@article{FeniciaEtAl:2008,
    abstract = {Lack of data is one of the main limitations for hydrological modeling. However, it is often used as a justification for over
                     simplifying, poorly performing models. If we want to enhance our understanding of hydrological systems, it is important to
                     fully exploit the information contained in the available data, and to learn from model deficiencies. In this paper, we propose
                     a methodology where we systematically update the model structure, progressively incorporating new hypotheses of catchment
                     behavior. We apply this methodology to the Alzette river basin in Luxembourg, showing how stepwise model improvement helps
                     to identify the behavior of this catchment. We show that the most significant improvement of the evolving model structure
                     is associated to the characterization of antecedent wetness. This is improved accounting for interception, which affects vertical
                     storage distribution, and accounting for rainfall spatial heterogeneity, which influences storage variations in the horizontal
                     dimension. Overall, our results suggested that, due to the damping effect of the basin, the description of fast catchment
                     response benefits more from spatially distributed information than that of slow catchment response.
                  },
    author = {Fenicia, Fabrizio and Savenije, Hubert H. G. and Matgen, Patrick and Pfister, Laurent},
    citeulike-article-id = {5656149},
    citeulike-linkout-0 = {http://www.agu.org/pubs/crossref/2008/2006WR005563.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1029/2006WR005563},
    day = {3},
    doi = {10.1029/2006WR005563},
    issn = {0043-1397},
    journal = {Water Resources Research},
    keywords = {systems, topdown},
    month = {January},
    number = {1},
    pages = {W01402+},
    posted-at = {2009-08-27 08:31:49},
    priority = {5},
    title = {Understanding catchment behavior through stepwise model concept improvement},
    url = {http://dx.doi.org/10.1029/2006WR005563},
    volume = {44},
    year = {2008}
}

@article{WagenerEtAl:2003,
    abstract = {Conceptual modelling requires the identification of a suitable model structure and the estimation of parameter values through calibration against observed data. A lack of objective approaches to evaluate model structures and the inability of calibration procedures to distinguish between the suitability of different parameter sets are major sources of uncertainty in current modelling procedures. This paper presents an approach analysing the performance of the model in a dynamic fashion resulting in an improved use of available information. Model structures can be evaluated with respect to the failure of individual components, and periods of high information content for specific parameters can be identified. The procedure is termed dynamic identifiability analysis (DYNIA) and is applied to a model structure built from typical conceptual components. Copyright {\copyright} 2003 John Wiley \& Sons, Ltd.},
    address = {Department of Civil and Environmental Engineering, Imperial College of Science, Technology and Medicine, Imperial College Road, London SW7 2BU, UK; Department of Hydrology and Water Resources, University of Arizona, Tucson, AZ, USA},
    author = {Wagener, T. and McIntyre, N. and Lees, M. J. and Wheater, H. S. and Gupta, H. V.},
    citeulike-article-id = {4951806},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hyp.1135},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/102526843/ABSTRACT},
    doi = {10.1002/hyp.1135},
    issn = {1099-1085},
    journal = {Hydrological Processes},
    keywords = {sensitivity, timeseries},
    number = {2},
    pages = {455--476},
    posted-at = {2009-08-27 08:21:28},
    priority = {2},
    title = {Towards reduced uncertainty in conceptual rainfall-runoff modelling: dynamic identifiability analysis},
    url = {http://dx.doi.org/10.1002/hyp.1135},
    volume = {17},
    year = {2003}
}

@article{Young:2003,
    abstract = {The data-based mechanistic (DBM) approach to modelling has developed as a stochastic, ?top-down? response to the problems associated with the deterministic, ?bottom-up? approach. As such, it can be compared with the deterministic, top-down modelling methods that have been attracting attention recently in the hydrological literature. Using catchment-scale rainfall-flow modelling as an example, this paper compares the inductive DBM approach with its hypothetico-deductive, deterministic alternative and shows how they can be used to identify and estimate low-order, nonlinear models of the rainfall-flow dynamics in the River Hodder catchment of northwest England based on a limited set of rainfall-flow data. Copyright {\copyright} 2003 John Wiley \& Sons, Ltd.},
    address = {Centre for Research on Environmental Systems and Statistics, Lancaster University, Lancaster LA1 4YQ, UK; Centre for Resource and Environmental Studies, Institute of Advanced Studies, Australian National University, Canberra, ACT 2020, Australia},
    author = {Young, Peter},
    citeulike-article-id = {763816},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hyp.1328},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/104547983/ABSTRACT},
    day = {15},
    doi = {10.1002/hyp.1328},
    issn = {0885-6087},
    journal = {Hydrological Processes},
    keywords = {timeseries, topdown},
    month = {August},
    number = {11},
    pages = {2195--2217},
    posted-at = {2009-08-26 02:48:01},
    priority = {0},
    title = {Top-down and data-based mechanistic modelling of rainfall-flow dynamics at the catchment scale},
    url = {http://dx.doi.org/10.1002/hyp.1328},
    volume = {17},
    year = {2003}
}

@article{Savenije:2009,
    abstract = {Hydrological modelling is the same as developing and encoding a hydrological theory. A hydrological model is not a tool but a hypothesis. The whole discussion about the inadequacy of hydrological models we have witnessed of late, is related to the wrong concept of what a model is. Good models don't exist. Instead of looking for the "best" model, we should aim at developing better models. The process of modelling should be top-down, learning from the data while at the same time connection should be established with underlying physical theory (bottom-up). As a result of heterogeneity occurring at all scales in hydrology, there always remains a need for calibration of models. This implies that we need tailor-made and site-specific models. Only flexible models are fit for this modelling process, as opposed to most of the established software or "one-size-fits-all" models. The process of modelling requires imagination, inspiration, creativity, ingenuity, experience and skill. These are qualities that belong to the field of art. Hydrology is an art as much as it is science and engineering.},
    author = {Savenije, H. H. G.},
    citeulike-article-id = {5629172},
    citeulike-linkout-0 = {http://www.hydrol-earth-syst-sci.net/13/157/2009/},
    day = {18},
    journal = {Hydrology and Earth System Sciences},
    keywords = {grand, topdown},
    month = {February},
    number = {2},
    pages = {157--161},
    posted-at = {2009-08-24 02:37:43},
    priority = {0},
    publisher = {Copernicus Publications},
    title = {HESS Opinions: The art of hydrology},
    url = {http://www.hydrol-earth-syst-sci.net/13/157/2009/},
    volume = {13},
    year = {2009}
}

@article{WagenerEtAl:2009,
    abstract = {Advances in our ability to model complex environmental systems are currently driven by at least four needs: (1) the need for the inclusion of uncertainty in monitoring, modelling and decision-making; (2) the need to provide environmental predictions everywhere; (3) the need to predict the impacts of environmental change; and (4) the need to adaptively evolve observation networks to better resolve environmental systems and embrace sensing innovations. Satisfying these needs will require improved theory, improved models and improved frameworks for making and evaluating predictions. All of these improvements should result in the long-term evolution and improvement of observation systems. In the context of this paper we discuss current bottlenecks and opportunities for advancing environmental modelling with and without local observations of system response. More realistic representations of real-world thresholds, nonlinearities and feedbacks motivates the use of more complex models as well as the consequent need for more rigorous evaluations of model performance. In the case of gauged systems, we find that global sensitivity analysis provides a widely underused tool for evaluating models\&\#39; assumptions and estimating the information content of data. In the case of ungauged systems, including the modelling of environmental change impacts, we propose that the definition of constraints on the expected system response provides a promising way forward. Examples of our own work are included to support the conclusions of this discussion paper. Overall, we conclude that an important bottleneck currently limiting environmental predictions lies in how our model evaluation and identification approaches are extracting, using and evolving the information available for environmental systems at the watershed scale.},
    author = {Wagener, Thorsten and Reed, Patrick and van Werkhoven, Kathryn and Tang, Yong and Zhang, Zhenxing},
    citeulike-article-id = {5629084},
    citeulike-linkout-0 = {http://dx.doi.org/10.2166/hydro.2009.040},
    citeulike-linkout-1 = {http://www.iwaponline.com/jh/011/jh0110266.htm},
    doi = {10.2166/hydro.2009.040},
    journal = {Journal of Hydroinformatics},
    keywords = {grand, sensitivity, systems},
    number = {3},
    posted-at = {2009-08-24 01:22:10},
    priority = {4},
    publisher = {IWA Publishing},
    title = {Advances in the identification and evaluation of complex environmental systems models},
    url = {http://dx.doi.org/10.2166/hydro.2009.040},
    volume = {11},
    year = {2009}
}

@article{WagenerKollat:2007,
    abstract = {The detailed evaluation of mathematical models and the consideration of uncertainty in the modeling of hydrological and environmental systems are of increasing importance, and are sometimes even demanded by decision makers. At the same time, the growing complexity of models to represent real-world systems makes it more and more difficult to understand model behavior, sensitivities and uncertainties. The Monte Carlo Analysis Toolbox (MCAT) is a Matlab library of visual and numerical analysis tools for the evaluation of hydrological and environmental models. Input to the MCAT is the result of a Monte Carlo or population evolution based sampling of the parameter space of the model structure under investigation. The MCAT can be used off-line, i.e. it does not have to be connected to the evaluated model, and can thus be used for any model for which an appropriate sampling can be performed. The MCAT contains tools for the evaluation of performance, identifiability, sensitivity, predictive uncertainty and also allows for the testing of hypotheses with respect to the model structure used. In addition to research applications, the MCAT can be used as a teaching tool in courses that include the use of mathematical models.},
    author = {Wagener, T. and Kollat, J.},
    citeulike-article-id = {2896234},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2006.06.017},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1364815206001630},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6VHC-4KTVP98-2/1/450631c694fa1fe42e7c8d90b98860ee},
    doi = {10.1016/j.envsoft.2006.06.017},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {sensitivity, software},
    month = {July},
    number = {7},
    pages = {1021--1033},
    posted-at = {2009-08-24 01:12:56},
    priority = {3},
    title = {Numerical and visual evaluation of hydrological and environmental models using the Monte Carlo analysis toolbox},
    url = {http://dx.doi.org/10.1016/j.envsoft.2006.06.017},
    volume = {22},
    year = {2007}
}

@article{LiuEtAl:2008,
    abstract = {The call for more effective integration of science and decision making is ubiquitous in environmental management. While scientists often complain that their input is ignored by decision makers, the latter have also expressed dissatisfaction that critical information for their decision making is often not readily available or accessible to them, or not presented in a usable form. It has been suggested that scientists need to produce more  ” usable” information with enhanced credibility, legitimacy, and saliency to ensure the adoption of research results. In basin-scale management of coupled human-water systems, water resources managers, like other decision makers, are frequently confronted with the need to make major decisions in the face of high system complexity and uncertainty. The integration of useful and relevant scientific information is necessary and critical to enable informed decision-making. This paper describes the main aspects of what has been learned in the process of supporting sustainable water resources planning and management in the semi-arid southwestern United States by means of integrated modeling. Our experience indicates that particular attention must be paid to the proper definition of focus questions, explicit conceptual modeling, a suitable modeling strategy, and a formal scenario analysis approach in order to facilitate the development of  ” usable” scientific information. We believe that these lessons and insights can be useful to other scientific efforts in the broader area of linking environmental science with decision making.},
    author = {Liu, Y. and Gupta, H. and Springer, E. and Wagener, T.},
    citeulike-article-id = {2600333},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.envsoft.2007.10.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S136481520700206X},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6VHC-4RWHXHH-1/2/f80b8ea42e3b4c98820ce1d7a5609703},
    day = {21},
    doi = {10.1016/j.envsoft.2007.10.007},
    issn = {13648152},
    journal = {Environmental Modelling \& Software},
    keywords = {integration, participation},
    month = {February},
    number = {7},
    pages = {846--858},
    posted-at = {2009-08-24 01:07:49},
    priority = {2},
    title = {Linking science with environmental decision making: Experiences from an integrated modeling approach to supporting sustainable water resources management},
    url = {http://dx.doi.org/10.1016/j.envsoft.2007.10.007},
    volume = {23},
    year = {2008}
}


  @Manual{coda,
    title = {coda: Output analysis and diagnostics for MCMC},
    author = {Martyn Plummer and Nicky Best and Kate Cowles and Karen Vines},
    year = {2010},
    note = {R package version 0.13-5},
    url = {http://CRAN.R-project.org/package=coda},
  }

  @Manual{DEoptim,
    title = {The 'DEoptim' Package: Differential Evolution Optimization in 'R'},
    author = {David Ardia and Katharine Mullen},
    year = {2010},
    note = {R package version 2.0-5},
  }

  @Manual{dream,
    title = {dream: DiffeRential Evolution Adaptive Metropolis},
    author = {Jasper Vrugt and CJF ter Braak and et al. (R port by Joseph Guillaume)},
    year = {2010},
    note = {R package version 0.2-0},
    url = {http://dream.r-forge.r-project.org/},
  }

  @Manual{forecast,
    title = {forecast: Forecasting functions for time series},
    author = {Rob J Hyndman},
    year = {2010},
    note = {R package version 2.05},
    url = {http://CRAN.R-project.org/package=forecast},
  }

@Manual{Pujol:2008,
  title = {sensitivity: Sensitivity Analysis},
  author = {Gilles Pujol},
  year = {2008},
  note = {R package version 1.4-0},
}

  @Manual{lattice,
    title = {lattice: Lattice Graphics},
    author = {Deepayan Sarkar},
    year = {2010},
    note = {R package version 0.18-5},
    url = {http://r-forge.r-project.org/projects/lattice/},
  }

  @Manual{latticeExtra,
    title = {latticeExtra: Extra Graphical Utilities Based on Lattice},
    author = {Deepayan Sarkar and Felix Andrews},
    year = {2010},
    note = {R package version 0.6-12},
    url = {http://latticeextra.r-forge.r-project.org/},
  }

  @Manual{playwith,
    title = {playwith: A GUI for interactive plots using GTK+},
    author = {Felix Andrews},
    year = {2010},
    note = {R package version 0.9-45},
    url = {http://CRAN.R-project.org/package=playwith},
  }

